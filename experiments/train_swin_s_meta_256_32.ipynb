{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56e82235",
   "metadata": {},
   "source": [
    "このNotebookは、モデルを学習させるために作られたものである。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79324f0b",
   "metadata": {},
   "source": [
    "# 1. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd18a0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Configuration\n",
    "RUN_NAME = \"swin-s-meta\"\n",
    "SAVE_DIR = \"../results/\" + RUN_NAME\n",
    "TEST_RUN = False\n",
    "SEED = 42\n",
    "DEVICE = \"cuda\"\n",
    "\n",
    "# Input Data Configuration\n",
    "IMAGE_SIZE = 256\n",
    "NUM_SLICES = 32\n",
    "BATCH_SIZE = 5\n",
    "LABEL_NAMES = [\n",
    "    # 13 classes\n",
    "    'Left Infraclinoid Internal Carotid Artery',\n",
    "    'Right Infraclinoid Internal Carotid Artery',\n",
    "    'Left Supraclinoid Internal Carotid Artery',\n",
    "    'Right Supraclinoid Internal Carotid Artery',\n",
    "    'Left Middle Cerebral Artery',\n",
    "    'Right Middle Cerebral Artery',\n",
    "    'Anterior Communicating Artery',\n",
    "    'Left Anterior Cerebral Artery',\n",
    "    'Right Anterior Cerebral Artery',\n",
    "    'Left Posterior Communicating Artery',\n",
    "    'Right Posterior Communicating Artery',\n",
    "    'Basilar Tip',\n",
    "    'Other Posterior Circulation',\n",
    "    # 'Aneurysm Present',\n",
    "]\n",
    "NUM_LABELS = len(LABEL_NAMES)\n",
    "\n",
    "# Training Configuration\n",
    "NUM_EPOCHS = 20\n",
    "PATIENCE = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e01f6b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_NAME = RUN_NAME + f'-{IMAGE_SIZE}-{NUM_SLICES}'\n",
    "\n",
    "# Weights & Biases Configuration\n",
    "if TEST_RUN:\n",
    "    USE_WANDB = False\n",
    "else:\n",
    "    USE_WANDB = True\n",
    "WANDB_INIT = {\n",
    "    'project': 'RSNA-IAD',\n",
    "    'group': 'Image Classification',\n",
    "    'job_type': 'training_model',\n",
    "    'save_code': True,\n",
    "}\n",
    "ARTIFACT = {\n",
    "    'name': RUN_NAME,\n",
    "    'type': 'model, optimizer, scheduler',\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9dff7a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Configuration:\n",
    "    \n",
    "    # Run\n",
    "    run_name = RUN_NAME\n",
    "    save_dir = SAVE_DIR\n",
    "    test_run = TEST_RUN\n",
    "    seed = SEED\n",
    "    device = DEVICE\n",
    "    \n",
    "    # Input Data\n",
    "    image_size = IMAGE_SIZE\n",
    "    num_slices = NUM_SLICES\n",
    "    batch_size = BATCH_SIZE\n",
    "    label_names = LABEL_NAMES\n",
    "    num_labels = NUM_LABELS\n",
    "    \n",
    "    # Training\n",
    "    num_epochs = NUM_EPOCHS\n",
    "    patience = PATIENCE\n",
    "    \n",
    "    # Weights & Biases\n",
    "    use_wandb = USE_WANDB\n",
    "    wandb_init = WANDB_INIT\n",
    "    artifact = ARTIFACT\n",
    "\n",
    "CFG = Configuration\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42800cbd",
   "metadata": {},
   "source": [
    "# 2. Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b9b7111",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "from typing import List, Dict, Optional, Tuple\n",
    "from IPython.display import display\n",
    "import datetime\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Data handling\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, StratifiedKFold\n",
    "from skmultilearn.model_selection import iterative_train_test_split\n",
    "\n",
    "# Medical imaging\n",
    "import pydicom\n",
    "import cv2\n",
    "\n",
    "# Machine Lerning \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.amp import autocast\n",
    "import torchvision\n",
    "import timm\n",
    "\n",
    "# Transformations\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import PIL.Image as Image\n",
    "\n",
    "# Experiment Management\n",
    "import wandb\n",
    "\n",
    "# Competition API\n",
    "# import kaggle_evaluation.rsna_inference_server\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17163be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# datetime for unique checkpoint filenames\n",
    "date_time = datetime.datetime.now()\n",
    "date_time = date_time.strftime('%Y-%m-%d_%H-%M-%S')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35d0f324",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_random_seeds(seed=CFG.seed, deterministic=False):\n",
    "    \"\"\"\n",
    "    Set random seed.\n",
    "    \n",
    "    Args:\n",
    "        seed (int): Seed to be used.\n",
    "        deterministic (bool): Whether to set the deterministic option for\n",
    "            CUDNN backend, i.e., set `torch.backends.cudnn.deterministic`\n",
    "            to True and `torch.backends.cudnn.benchmark` to False.\n",
    "            Default: False.\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "    if deterministic:\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "\n",
    "set_random_seeds(seed=CFG.seed, deterministic=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf18207",
   "metadata": {},
   "source": [
    "# 3. Weights & Biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7df88fa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find swin-s-meta-256-32.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mataracsia\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\emanon\\Library\\Kaggle\\rsna-intracranial-aneurysm-detection_ver2\\experiments\\wandb\\run-20250927_002045-54y890ha</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ataracsia/RSNA-IAD/runs/54y890ha' target=\"_blank\">soft-energy-5</a></strong> to <a href='https://wandb.ai/ataracsia/RSNA-IAD' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ataracsia/RSNA-IAD' target=\"_blank\">https://wandb.ai/ataracsia/RSNA-IAD</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ataracsia/RSNA-IAD/runs/54y890ha' target=\"_blank\">https://wandb.ai/ataracsia/RSNA-IAD/runs/54y890ha</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if CFG.use_wandb:\n",
    "    os.environ['WANDB_NOTEBOOK_NAME'] = CFG.run_name\n",
    "    wandb.login()\n",
    "    run = wandb.init(**CFG.wandb_init)\n",
    "    artifact = wandb.Artifact(**CFG.artifact)\n",
    "else:\n",
    "    run = None\n",
    "    artifact = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce6b9cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def alert_by_wandb(title='', text=''):\n",
    "    wandb.alert(title, text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b593a9c",
   "metadata": {},
   "source": [
    "# 4. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71313d5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SwinWithMetaModel(\n",
       "  (backbone): SwinTransformer(\n",
       "    (patch_embed): PatchEmbed(\n",
       "      (proj): Conv2d(32, 96, kernel_size=(4, 4), stride=(4, 4))\n",
       "      (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (layers): Sequential(\n",
       "      (0): SwinTransformerStage(\n",
       "        (downsample): Identity()\n",
       "        (blocks): Sequential(\n",
       "          (0): SwinTransformerBlock(\n",
       "            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=96, out_features=96, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=96, out_features=384, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=384, out_features=96, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (1): SwinTransformerBlock(\n",
       "            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=96, out_features=96, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path1): DropPath(drop_prob=0.009)\n",
       "            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=96, out_features=384, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=384, out_features=96, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): DropPath(drop_prob=0.009)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): SwinTransformerStage(\n",
       "        (downsample): PatchMerging(\n",
       "          (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (reduction): Linear(in_features=384, out_features=192, bias=False)\n",
       "        )\n",
       "        (blocks): Sequential(\n",
       "          (0): SwinTransformerBlock(\n",
       "            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path1): DropPath(drop_prob=0.017)\n",
       "            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): DropPath(drop_prob=0.017)\n",
       "          )\n",
       "          (1): SwinTransformerBlock(\n",
       "            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path1): DropPath(drop_prob=0.026)\n",
       "            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): DropPath(drop_prob=0.026)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): SwinTransformerStage(\n",
       "        (downsample): PatchMerging(\n",
       "          (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (reduction): Linear(in_features=768, out_features=384, bias=False)\n",
       "        )\n",
       "        (blocks): Sequential(\n",
       "          (0): SwinTransformerBlock(\n",
       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path1): DropPath(drop_prob=0.035)\n",
       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): DropPath(drop_prob=0.035)\n",
       "          )\n",
       "          (1): SwinTransformerBlock(\n",
       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path1): DropPath(drop_prob=0.043)\n",
       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): DropPath(drop_prob=0.043)\n",
       "          )\n",
       "          (2): SwinTransformerBlock(\n",
       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path1): DropPath(drop_prob=0.052)\n",
       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): DropPath(drop_prob=0.052)\n",
       "          )\n",
       "          (3): SwinTransformerBlock(\n",
       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path1): DropPath(drop_prob=0.061)\n",
       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): DropPath(drop_prob=0.061)\n",
       "          )\n",
       "          (4): SwinTransformerBlock(\n",
       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path1): DropPath(drop_prob=0.070)\n",
       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): DropPath(drop_prob=0.070)\n",
       "          )\n",
       "          (5): SwinTransformerBlock(\n",
       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path1): DropPath(drop_prob=0.078)\n",
       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): DropPath(drop_prob=0.078)\n",
       "          )\n",
       "          (6): SwinTransformerBlock(\n",
       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path1): DropPath(drop_prob=0.087)\n",
       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): DropPath(drop_prob=0.087)\n",
       "          )\n",
       "          (7): SwinTransformerBlock(\n",
       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path1): DropPath(drop_prob=0.096)\n",
       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): DropPath(drop_prob=0.096)\n",
       "          )\n",
       "          (8): SwinTransformerBlock(\n",
       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path1): DropPath(drop_prob=0.104)\n",
       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): DropPath(drop_prob=0.104)\n",
       "          )\n",
       "          (9): SwinTransformerBlock(\n",
       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path1): DropPath(drop_prob=0.113)\n",
       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): DropPath(drop_prob=0.113)\n",
       "          )\n",
       "          (10): SwinTransformerBlock(\n",
       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path1): DropPath(drop_prob=0.122)\n",
       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): DropPath(drop_prob=0.122)\n",
       "          )\n",
       "          (11): SwinTransformerBlock(\n",
       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path1): DropPath(drop_prob=0.130)\n",
       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): DropPath(drop_prob=0.130)\n",
       "          )\n",
       "          (12): SwinTransformerBlock(\n",
       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path1): DropPath(drop_prob=0.139)\n",
       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): DropPath(drop_prob=0.139)\n",
       "          )\n",
       "          (13): SwinTransformerBlock(\n",
       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path1): DropPath(drop_prob=0.148)\n",
       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): DropPath(drop_prob=0.148)\n",
       "          )\n",
       "          (14): SwinTransformerBlock(\n",
       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path1): DropPath(drop_prob=0.157)\n",
       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): DropPath(drop_prob=0.157)\n",
       "          )\n",
       "          (15): SwinTransformerBlock(\n",
       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path1): DropPath(drop_prob=0.165)\n",
       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): DropPath(drop_prob=0.165)\n",
       "          )\n",
       "          (16): SwinTransformerBlock(\n",
       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path1): DropPath(drop_prob=0.174)\n",
       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): DropPath(drop_prob=0.174)\n",
       "          )\n",
       "          (17): SwinTransformerBlock(\n",
       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path1): DropPath(drop_prob=0.183)\n",
       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): DropPath(drop_prob=0.183)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): SwinTransformerStage(\n",
       "        (downsample): PatchMerging(\n",
       "          (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "          (reduction): Linear(in_features=1536, out_features=768, bias=False)\n",
       "        )\n",
       "        (blocks): Sequential(\n",
       "          (0): SwinTransformerBlock(\n",
       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path1): DropPath(drop_prob=0.191)\n",
       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): DropPath(drop_prob=0.191)\n",
       "          )\n",
       "          (1): SwinTransformerBlock(\n",
       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path1): DropPath(drop_prob=0.200)\n",
       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): DropPath(drop_prob=0.200)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (head): ClassifierHead(\n",
       "      (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Identity())\n",
       "      (drop): Dropout(p=0.3, inplace=False)\n",
       "      (fc): Identity()\n",
       "      (flatten): Identity()\n",
       "    )\n",
       "  )\n",
       "  (meta_features): Sequential(\n",
       "    (0): Linear(in_features=2, out_features=16, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.2, inplace=False)\n",
       "    (3): Linear(in_features=16, out_features=32, bias=True)\n",
       "    (4): ReLU()\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=800, out_features=512, bias=True)\n",
       "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout(p=0.3, inplace=False)\n",
       "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): ReLU()\n",
       "    (7): Dropout(p=0.3, inplace=False)\n",
       "    (8): Linear(in_features=256, out_features=13, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class SwinWithMetaModel(nn.Module):\n",
    "    def __init__(self, model_name, pretrained=False,\n",
    "                 num_classes=CFG.num_labels, drop_rate=0.3,\n",
    "                 drop_path_rate=0.2):\n",
    "        super().__init__()\n",
    "        self.model_name = model_name\n",
    "        \n",
    "        if model_name == 'swin_s':\n",
    "            self.backbone = timm.create_model(\n",
    "                'swin_small_patch4_window7_224',\n",
    "                pretrained=pretrained,\n",
    "                img_size=CFG.image_size,\n",
    "                drop_rate=drop_rate,\n",
    "                drop_path_rate=drop_path_rate,\n",
    "                global_poopling='',\n",
    "                num_classes=0)\n",
    "            \n",
    "            # input layer modification: 3 channels -> CFG.num_slices channels\n",
    "            self.backbone.patch_embed.proj = nn.Conv2d(\n",
    "                in_channels=CFG.num_slices,\n",
    "                out_channels=96,\n",
    "                kernel_size=4,\n",
    "                stride=4,\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(f\"Model {model_name} is not supported.\")\n",
    "        \n",
    "        self.meta_features = nn.Sequential(\n",
    "            nn.Linear(2, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(16, 32),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # According to \"LB #1\"\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(768 + 32, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(drop_rate),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(drop_rate),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, images, meta): \n",
    "        image_features = self.backbone(images)\n",
    "        meta_fieatures = self.meta_features(meta)\n",
    "        x = torch.cat([image_features, meta_fieatures], dim=1)\n",
    "        x = self.classifier(x)\n",
    "        x = torch.nn.Sigmoid()(x)\n",
    "        return x\n",
    "\n",
    "model = SwinWithMetaModel(model_name='swin_s', pretrained=False)\n",
    "model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a47ab9",
   "metadata": {},
   "source": [
    "-> timm.createmodel(num_classes=0)とすると、最後のnn.Linear()がnn.Identity()になる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "13629b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "# https://docs.pytorch.org/vision/main/models/generated/torchvision.models.swin_s.html#torchvision.models.Swin_S_Weights\n",
    "\n",
    "# model = torchvision.models.swin_s(pretrained=False, num_classes=13)\n",
    "\n",
    "# model.features[0][0] = nn.Conv2d(\n",
    "#     in_channels=CFG.num_slices,\n",
    "#     out_channels=96,\n",
    "#     kernel_size=4,\n",
    "#     stride=4,\n",
    "#     padding=0\n",
    "# )\n",
    "# model.head = nn.Sequential(\n",
    "#     nn.Linear(in_features=768, out_features=512),\n",
    "#     nn.BatchNorm1d(512),\n",
    "#     nn.ReLU(),\n",
    "#     nn.Dropout(0.3),\n",
    "#     nn.Linear(512, 256),\n",
    "#     nn.BatchNorm1d(256),\n",
    "#     nn.ReLU(),\n",
    "#     nn.Dropout(0.3),\n",
    "#     nn.Linear(256, len(CFG.label_names))\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "acbea94e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All parameters is in cuda\n"
     ]
    }
   ],
   "source": [
    "model.to(device)\n",
    "\n",
    "is_in_cuda_list = []\n",
    "\n",
    "for name, parameter in model.named_parameters():\n",
    "    # determination of cuda and its storage\n",
    "    is_in_cuda_list.append(parameter.is_cuda)\n",
    "    \n",
    "if all(is_in_cuda_list):\n",
    "    print('All parameters is in cuda')\n",
    "        \n",
    "else:\n",
    "    print('One of the parameters is not in the cuda.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "206e8241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters())\n",
    "\n",
    "# Loss Function\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Schedulers\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "    optimizer,\n",
    "    T_max=CFG.num_epochs,\n",
    "    eta_min=1e-6\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9314cd98",
   "metadata": {},
   "source": [
    "# 5. Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "97f1c259",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SeriesInstanceUID list\n",
    "series_list = os.listdir(f'../series_npy/{CFG.image_size}')\n",
    "\n",
    "# .npy path DataFrame\n",
    "image_path_df = pd.read_csv(f'../npy_path/image_{CFG.image_size}_path_df.csv')\n",
    "\n",
    "# Meta DataFrame\n",
    "meta_df = pd.read_csv('../meta_data/meta.csv')\n",
    "\n",
    "# Label DataFrame\n",
    "label_df = pd.read_csv(f'../train.csv')\n",
    "label_df = label_df[['SeriesInstanceUID'] + CFG.label_names]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b3aaf1a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SeriesInstanceUID</th>\n",
       "      <th>modalisy</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4296</th>\n",
       "      <td>1.2.826.0.1.3680043.8.498.98697915765488213704...</td>\n",
       "      <td>MR</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      SeriesInstanceUID modalisy  age  sex\n",
       "4296  1.2.826.0.1.3680043.8.498.98697915765488213704...       MR   60    1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_df.loc[meta_df['SeriesInstanceUID'] == '1.2.826.0.1.3680043.8.498.98697915765488213704603518081182644986']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "020d475a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def minmax_scaling(images: torch.Tensor) -> torch.Tensor:\n",
    "    if torch.max(images) > 1.0:\n",
    "        images = images / 255\n",
    "    return images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b4e6ade1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for training\n",
    "train_transform = A.Compose(\n",
    "    [\n",
    "        # # Elastic Transform <- あとで試したい\n",
    "        # A.ElasticTransform( p=0.5),\n",
    "        \n",
    "        # Rotation\n",
    "        A.Rotate(limit=(-3, 3), p=0.5, border_mode=cv2.BORDER_WRAP,  # cv2.BORDER_WRAP,\n",
    "                 seed=CFG.seed\n",
    "        ),\n",
    "        \n",
    "        # Normalization\n",
    "        A.Normalize(normalization='min_max'),\n",
    "        \n",
    "        # ToTensor\n",
    "        ToTensorV2(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# for inference\n",
    "inference_transform = A.Compose(\n",
    "    [\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2()\n",
    "    ]\n",
    ")\n",
    "    \n",
    "# for TTA\n",
    "tta_transform = A.Compose(\n",
    "    [\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "            \n",
    "        # Horizontal flip\n",
    "        A.HorizontalFlip(p=1.0),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        \n",
    "        # Vertical flip\n",
    "        A.VerticalFlip(p=1.0),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        \n",
    "        # 90 degree rotation\n",
    "        A.RandomRotate90(p=1.0),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        \n",
    "        # ↓ Original\n",
    "        # Sharpen\n",
    "        A.Sharpen(alpha=(0, 1.0), p=1.0),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        \n",
    "        ToTensorV2(),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7e1ffd20",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseDataset(torch.utils.data.Dataset):\n",
    "    '''\n",
    "    Datasetの__getitem__()は、num_slicesの枚数分だけ画像を出力する。\n",
    "    \n",
    "    Arguments:\n",
    "    - series_list: 画像のSeriesInstanceUIDのリスト\n",
    "    - image_path_df: 画像のパスを含むDataFrame\n",
    "    - meta_df: 患者のメタデータが入ったDataFrame\n",
    "    - label_df: ラベルが入ったDataFrame\n",
    "    - num_slices: 1つのシリーズから抽出するスライス数\n",
    "    - transforms: 画像変換のためのAlbumentationsのComposeオブジェクト\n",
    "    '''\n",
    "    def __init__(self,\n",
    "                 series_list: list,\n",
    "                 image_path_df=image_path_df,\n",
    "                 meta_df=meta_df,\n",
    "                 label_df=label_df,\n",
    "                 transforms=None\n",
    "        ):\n",
    "        self.series_list = series_list\n",
    "        self.image_path_df = image_path_df\n",
    "        self.meta_df = meta_df\n",
    "        self.label_df = label_df\n",
    "        self.transforms = transforms\n",
    "        self.num_slices = CFG.num_slices\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.series_list)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Index to SeriesInstanceUID\n",
    "        series_id = self.series_list[index]\n",
    "        \n",
    "        # SeriesInstanceUID to Image Path\n",
    "        image_path_df = self.image_path_df[\n",
    "            self.image_path_df['series_id'] == series_id\n",
    "        ].reset_index(drop=True)\n",
    "        \n",
    "        # Load Images\n",
    "        indices = np.linspace(0,\n",
    "                              len(image_path_df) - 1,\n",
    "                              self.num_slices).astype(np.int32)\n",
    "        # Stack images to (H, W, CFG.num_slices)\n",
    "        images = []\n",
    "        for i in indices:\n",
    "            image_path = image_path_df.loc[i, 'npy_path']\n",
    "            image = np.load(image_path).astype(np.uint8)\n",
    "            images.append(image)\n",
    "        images = np.stack(images, axis=-1)\n",
    "        \n",
    "        # Transform\n",
    "        if self.transforms:\n",
    "            # ToTensorV2はnumpy.ndarrayをtorch.Tensorに変換する\n",
    "            augmented = self.transforms(image=images)\n",
    "            images = augmented['image']\n",
    "        else:\n",
    "            images = torch.tensor(images, dtype=torch.float32)\n",
    "            images = torch.permute(images, (2, 0, 1))\n",
    "            # Normlization\n",
    "            if torch.max(images) > 1.0:\n",
    "                images = images / 255\n",
    "                \n",
    "        # Meta data\n",
    "        meta = self.meta_df.loc[\n",
    "            self.meta_df['SeriesInstanceUID'] == series_id, ['age', 'sex']\n",
    "        ]\n",
    "        age = min(meta['age'].values[0], 100)\n",
    "        age = age / 100\n",
    "        sex = meta['sex'].values[0]\n",
    "        meta = torch.tensor([age, sex], dtype=torch.float32)\n",
    "\n",
    "        # Labels\n",
    "        labels = self.label_df.loc[\n",
    "            self.label_df['SeriesInstanceUID']==series_id, \\\n",
    "                CFG.label_names].values\n",
    "        labels = torch.tensor(labels, dtype=torch.float32)\n",
    "        labels = torch.squeeze(labels, dim=0)\n",
    "        \n",
    "        return (images, meta, labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15340c5a",
   "metadata": {},
   "source": [
    "# 6. DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "86d0077f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataloaders():\n",
    "\n",
    "    series = label_df[[\"SeriesInstanceUID\"]].values\n",
    "    labels = label_df[CFG.label_names].values\n",
    "\n",
    "    if CFG.test_run:\n",
    "        # As the absolute number of data points cannot be specified,\n",
    "        # split is executed in two stages.\n",
    "        train_series, train_labels, val_series, _ = iterative_train_test_split(\n",
    "            series, labels, test_size=(1/len(series)) \\\n",
    "                * 2\n",
    "        )\n",
    "        _, _, train_series, train_labels = iterative_train_test_split(\n",
    "            train_series, train_labels, test_size=(1/len(series)) \\\n",
    "                * 2\n",
    "        )\n",
    "        \n",
    "    else:\n",
    "        train_series, _, val_series, _ = \\\n",
    "            iterative_train_test_split(\n",
    "                series, labels, test_size=0.2\n",
    "            )\n",
    "\n",
    "    # 2 dimensions -> 1 dimension\n",
    "    train_series, val_series = train_series.flatten(), val_series.flatten()\n",
    "    # train_series = [\n",
    "        # '1.2.826.0.1.3680043.8.498.10034081836061566510187499603024895557',\n",
    "        # '1.2.826.0.1.3680043.8.498.10034081836061566510187499603024895557'\n",
    "    # ]\n",
    "    print(f\"Train size: {len(train_series)}, Val size: {len(val_series)}\")\n",
    "\n",
    "    # train_image_path_df = \\\n",
    "    #     image_path_df[image_path_df['series_id'] \\\n",
    "    #     .isin(train_series)].reset_index(drop=True)\n",
    "    # val_image_path_df = \\\n",
    "    #     image_path_df[image_path_df['series_id'] \\\n",
    "    #     .isin(val_series)].reset_index(drop=True)\n",
    "        \n",
    "    # train_label_df = label_df[label_df['SeriesInstanceUID']\n",
    "    #     .isin(train_series)].set_index('SeriesInstanceUID')\n",
    "    # val_label_df = label_df[label_df['SeriesInstanceUID']\n",
    "    #     .isin(val_series)].set_index('SeriesInstanceUID')\n",
    "\n",
    "    train_dataset = BaseDataset(\n",
    "        series_list=train_series,\n",
    "        transforms=train_transform\n",
    "    )\n",
    "    val_dataset = BaseDataset(\n",
    "        series_list=val_series,\n",
    "        transforms=train_transform # tta_transform\n",
    "    )\n",
    "    train_dataloader = torch.utils.data.DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=CFG.batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=0\n",
    "    )\n",
    "    val_dataloader = torch.utils.data.DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=CFG.batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=0\n",
    "    )\n",
    "\n",
    "    return train_dataset, train_dataloader, val_dataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c52a3a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataloaders():\n",
    "\n",
    "    series = label_df[[\"SeriesInstanceUID\"]].values\n",
    "    labels = label_df[CFG.label_names].values\n",
    "\n",
    "    if CFG.test_run:\n",
    "        # As the absolute number of data points cannot be specified,\n",
    "        # split is executed in two stages.\n",
    "        train_series, train_labels, val_series, _ = iterative_train_test_split(\n",
    "            series, labels, test_size=(1/len(series)) \\\n",
    "                * 2\n",
    "        )\n",
    "        _, _, train_series, train_labels = iterative_train_test_split(\n",
    "            train_series, train_labels, test_size=(1/len(series)) \\\n",
    "                * 2\n",
    "        )\n",
    "        \n",
    "    else:\n",
    "        train_series, _, val_series, _ = iterative_train_test_split(\n",
    "            series, labels, test_size=0.2\n",
    "        )\n",
    "\n",
    "    # 2 dimensions -> 1 dimension\n",
    "    train_series, val_series = train_series.flatten(), val_series.flatten()\n",
    "    # train_series = [\n",
    "        # '1.2.826.0.1.3680043.8.498.10034081836061566510187499603024895557',\n",
    "        # '1.2.826.0.1.3680043.8.498.10034081836061566510187499603024895557'\n",
    "    # ]\n",
    "    print(f\"Train size: {len(train_series)}, Val size: {len(val_series)}\")\n",
    "\n",
    "    # train_image_path_df = \\\n",
    "    #     image_path_df[image_path_df['series_id'] \\\n",
    "    #     .isin(train_series)].reset_index(drop=True)\n",
    "    # val_image_path_df = \\\n",
    "    #     image_path_df[image_path_df['series_id'] \\\n",
    "    #     .isin(val_series)].reset_index(drop=True)\n",
    "        \n",
    "    # train_label_df = label_df[label_df['SeriesInstanceUID']\n",
    "    #     .isin(train_series)].set_index('SeriesInstanceUID')\n",
    "    # val_label_df = label_df[label_df['SeriesInstanceUID']\n",
    "    #     .isin(val_series)].set_index('SeriesInstanceUID')\n",
    "\n",
    "    # Datasets\n",
    "    train_dataset = BaseDataset(\n",
    "        series_list=train_series,\n",
    "        transforms=train_transform\n",
    "    )\n",
    "    val_dataset = BaseDataset(\n",
    "        series_list=val_series,\n",
    "        transforms=train_transform # or tta_transform\n",
    "    )\n",
    "    \n",
    "    # Dataloaders\n",
    "    train_dataloader = torch.utils.data.DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=CFG.batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=0\n",
    "    )\n",
    "    val_dataloader = torch.utils.data.DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=CFG.batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=0\n",
    "    )\n",
    "\n",
    "    return  train_dataloader, val_dataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a41308ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000e+00, 1.0000e+00, 1.0000e+00, 5.0000e-01, 2.1997e-01, 3.9990e-01,\n",
       "        9.9023e-01, 1.0133e-06, 0.0000e+00, 0.0000e+00, 1.0000e+00],\n",
       "       dtype=torch.float16)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = torch.tensor([0, 1, 2, 0.5, 0.22, 0.4, 0.99, 0.000001, -1, -100, 10000])\n",
    "sample = torch.clip(sample, min=0, max=1).to(torch.float16)\n",
    "sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "536ec2e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 3478, Val size: 870\n"
     ]
    }
   ],
   "source": [
    "train_dataloader, val_dataloader = build_dataloaders()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "018ebc65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "# # 元の画像とどのくらい違いがあるかを確認\n",
    "\n",
    "# # 元の画像(.npy)\n",
    "# src = np.load(f'../series_npy/{CFG.image_size}/1.2.826.0.1.3680043.8.498.10034081836061566510187499603024895557/00012.npy')\n",
    "# print(np.unique(src))\n",
    "# ax[0].imshow(src)\n",
    "\n",
    "# # Datasetから取り出した画像\n",
    "# images, _ = train_dataset[0]\n",
    "# image = images[8].numpy()  # shape: [H, W]\n",
    "\n",
    "# # 0-1のfloatなら0-255に変換\n",
    "# if image.max() <= 1.0:\n",
    "#     image = (image * 255).astype(np.uint8)\n",
    "# else:\n",
    "#     image = image.astype(np.uint8)\n",
    "\n",
    "# ax[1].imshow(image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2b5b63f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pil_image = Image.fromarray(image)\n",
    "# display(pil_image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2732754",
   "metadata": {},
   "source": [
    "# 7. Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1161cd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count execution time for one epoch\n",
    "def count_time(start:float) -> float:\n",
    "    \n",
    "    elapsed_time = time.time() - start\n",
    "    elapsed_time /= 60\n",
    "    \n",
    "    return elapsed_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7d4611cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to save model, optimizer, scheduler\n",
    "def save_checkpoint(model, optimizer, scheduler, path=\"\"):\n",
    "    \n",
    "    path = path.replace('\\\\', '/')\n",
    "    \n",
    "    checkpoint = {\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'scheduler_state_dict': scheduler.state_dict() if scheduler is not None else None,\n",
    "    }\n",
    "    torch.save(checkpoint, path)\n",
    "\n",
    "# to load model, optimizer, scheduler\n",
    "def load_checkpoint(model, optimizer, scheduler, path=\"\"):\n",
    "    \n",
    "    path = path.replace('\\\\', '/')\n",
    "    \n",
    "    checkpoint = torch.load(path)\n",
    "    \n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    if scheduler is not None and checkpoint['scheduler_state_dict'] is not None:\n",
    "        scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "    \n",
    "    return model, optimizer, scheduler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "680cfa7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to log losses to W&B\n",
    "def log_by_wandb(time, losses):\n",
    "    epoch_data = {\n",
    "        'time': time,\n",
    "        'loss': losses,\n",
    "    }\n",
    "    wandb.log(epoch_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a98ad525",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to log checkpoint\n",
    "def log_artifact(run=run, artifact=artifact, checkpoint_path=\"\"):\n",
    "    artifact.add_file(checkpoint_path)\n",
    "    run.log_artifact(artifact)\n",
    "    print('Artifact was logged to W&B')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634e7cf3",
   "metadata": {},
   "source": [
    "# 8. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d6593236",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(epoch: int) -> Tuple[float, float]:\n",
    "    \n",
    "    print(f'----- Epoch {epoch + 1} -----')\n",
    "    \n",
    "    # Training\n",
    "    train_losses = []\n",
    "    model.train()\n",
    "    \n",
    "    for images, meta, labels in tqdm(train_dataloader):    \n",
    "        images = images.to(device)\n",
    "        meta = meta.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        with autocast(device_type=CFG.device):\n",
    "            outputs = model(images, meta)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_losses.append(loss.item())\n",
    "    \n",
    "    mean_train_loss = np.mean(train_losses)\n",
    "    print(f'Last output:', outputs[0])\n",
    "    print(f'Mean Train Loss: {mean_train_loss:.4f}')\n",
    "    \n",
    "    # Validation\n",
    "    val_losses = []\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, meta, labels in tqdm(val_dataloader):\n",
    "            images = images.to(device)\n",
    "            meta = meta.to(device)\n",
    "            labels = labels.to(device)\n",
    "            with autocast(device_type=CFG.device):\n",
    "                outputs = model(images, meta)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_losses.append(loss.item())\n",
    "        \n",
    "    mean_val_loss = np.mean(val_losses)\n",
    "    print(f'Mean Validation Loss: {mean_val_loss:.4f}')\n",
    "        \n",
    "    scheduler.step()\n",
    "        \n",
    "    return mean_train_loss, mean_val_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7148edc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "    os.makedirs(CFG.save_dir, exist_ok=True)\n",
    "    best_val_loss = np.inf\n",
    "    \n",
    "    for epoch in range(CFG.num_epochs):\n",
    "        \n",
    "        # Train & Validation\n",
    "        start_time = time.time()\n",
    "        train_loss, val_loss = train_one_epoch(epoch)\n",
    "        elapsed_time = count_time(start_time)\n",
    "        print(f'Elapsed time: {elapsed_time}')\n",
    "        \n",
    "        # Log to W&B\n",
    "        if CFG.use_wandb:\n",
    "            losses = {\n",
    "                'train_loss': train_loss,\n",
    "                'val_loss': val_loss\n",
    "            }\n",
    "            log_by_wandb(elapsed_time, losses)\n",
    "        \n",
    "        # Save all checkpoints\n",
    "        checkpoint_path = os.path.join(\n",
    "            CFG.save_dir,\n",
    "            f'checkpoint_{date_time}.pth'\n",
    "        )\n",
    "        checkpoint_path = checkpoint_path.replace('\\\\', '/')\n",
    "        save_checkpoint(model, optimizer, scheduler, checkpoint_path)\n",
    "        print(f'Checkpoint saved at {checkpoint_path}')\n",
    "        \n",
    "        # Save best checkpoint\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_checkpoint_path = os.path.join(\n",
    "                CFG.save_dir,\n",
    "                f'best_checkpoint_{date_time}.pth'\n",
    "            )\n",
    "            best_checkpoint_path = best_checkpoint_path.replace('\\\\', '/')\n",
    "            save_checkpoint(model, optimizer, scheduler, best_checkpoint_path)\n",
    "            print(f'Best checkpoint updated at {best_checkpoint_path}')\n",
    "    \n",
    "    # Log artifact to W&B\n",
    "    if CFG.use_wandb:\n",
    "        log_artifact(run, artifact, best_checkpoint_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "35083e4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Epoch 1 -----\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6839164fa7ea4dfbadbfb791729b1cd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/696 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last output: tensor([1.5843e-04, 2.3055e-04, 1.7536e-04, 1.4997e-04, 2.5129e-04, 3.5548e-04,\n",
      "        2.6941e-04, 3.4738e-04, 3.3021e-04, 2.1148e-04, 1.9872e-04, 2.1315e-04,\n",
      "        8.8871e-05], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<SelectBackward0>)\n",
      "Mean Train Loss: 0.7012\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4a1d30ef16e4951abef0284633bf18c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/174 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Validation Loss: 0.6932\n",
      "Elapsed time: 36.93630487918854\n",
      "Checkpoint saved at ../results/swin-s-meta/checkpoint_2025-09-27_00-20-44.pth\n",
      "Best checkpoint updated at ../results/swin-s-meta/best_checkpoint_2025-09-27_00-20-44.pth\n",
      "----- Epoch 2 -----\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04925e3bfad74f028a6d27de9a50e2d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/696 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last output: tensor([7.8440e-05, 2.2113e-05, 1.0639e-04, 4.2319e-05, 5.1856e-05, 6.8665e-05,\n",
      "        1.1593e-04, 3.8505e-05, 6.8128e-05, 4.3631e-05, 7.7844e-05, 5.6922e-05,\n",
      "        2.9564e-05], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<SelectBackward0>)\n",
      "Mean Train Loss: 0.6933\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95fd0b8770bd4b71a7b8a94c94ec4a36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/174 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Validation Loss: 0.6932\n",
      "Elapsed time: 35.02141271034876\n",
      "Checkpoint saved at ../results/swin-s-meta/checkpoint_2025-09-27_00-20-44.pth\n",
      "Best checkpoint updated at ../results/swin-s-meta/best_checkpoint_2025-09-27_00-20-44.pth\n",
      "----- Epoch 3 -----\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "871f689c7c264f12a24c09afc92b7ddc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/696 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last output: tensor([4.1664e-05, 9.3579e-06, 1.4961e-05, 2.1458e-05, 2.5690e-05, 1.2696e-05,\n",
      "        1.1921e-05, 1.0610e-05, 2.2650e-05, 2.3544e-05, 3.7372e-05, 8.4043e-06,\n",
      "        7.8678e-06], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<SelectBackward0>)\n",
      "Mean Train Loss: 0.6932\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71b64248251944dd9db30b2a15fdb26f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/174 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Validation Loss: 0.6932\n",
      "Elapsed time: 35.43645524183909\n",
      "Checkpoint saved at ../results/swin-s-meta/checkpoint_2025-09-27_00-20-44.pth\n",
      "Best checkpoint updated at ../results/swin-s-meta/best_checkpoint_2025-09-27_00-20-44.pth\n",
      "----- Epoch 4 -----\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6be7e26c4344016b8ca945d43933b7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/696 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last output: tensor([7.3314e-06, 1.8775e-05, 5.9605e-06, 1.2100e-05, 1.5080e-05, 2.8431e-05,\n",
      "        6.9737e-06, 2.4319e-05, 1.8954e-05, 1.2696e-05, 1.7107e-05, 2.7299e-05,\n",
      "        6.0797e-06], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<SelectBackward0>)\n",
      "Mean Train Loss: 0.6932\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b79fcac8cbad4922a3b775caecbec72a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/174 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Validation Loss: 0.6932\n",
      "Elapsed time: 36.61913451353709\n",
      "Checkpoint saved at ../results/swin-s-meta/checkpoint_2025-09-27_00-20-44.pth\n",
      "Best checkpoint updated at ../results/swin-s-meta/best_checkpoint_2025-09-27_00-20-44.pth\n",
      "----- Epoch 5 -----\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "911d63a42c354b5e95098084743b40be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/696 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last output: tensor([9.5963e-06, 9.0599e-06, 5.3048e-06, 1.3709e-05, 2.3246e-06, 2.9802e-06,\n",
      "        1.0073e-05, 6.3181e-06, 6.8545e-06, 8.3447e-06, 1.1027e-05, 5.8413e-06,\n",
      "        3.5763e-06], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<SelectBackward0>)\n",
      "Mean Train Loss: 0.6932\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33867f40f9c4475888803a732592a527",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/174 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Validation Loss: 0.6932\n",
      "Elapsed time: 37.09324551820755\n",
      "Checkpoint saved at ../results/swin-s-meta/checkpoint_2025-09-27_00-20-44.pth\n",
      "----- Epoch 6 -----\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6987f279d2ed418e93eda376b46900b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/696 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last output: tensor([1.6689e-06, 2.6226e-06, 1.4901e-06, 1.6689e-06, 3.0398e-06, 2.3246e-06,\n",
      "        2.4438e-06, 3.0398e-06, 3.1590e-06, 3.1590e-06, 2.6226e-06, 2.5630e-06,\n",
      "        3.0398e-06], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<SelectBackward0>)\n",
      "Mean Train Loss: 0.6932\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb0fa755f54a408c9bd1f1886c4afd36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/174 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Validation Loss: 0.6931\n",
      "Elapsed time: 37.11773673693339\n",
      "Checkpoint saved at ../results/swin-s-meta/checkpoint_2025-09-27_00-20-44.pth\n",
      "Best checkpoint updated at ../results/swin-s-meta/best_checkpoint_2025-09-27_00-20-44.pth\n",
      "----- Epoch 7 -----\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58d22242698c4e28a7cc2cccce817762",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/696 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last output: tensor([1.2815e-05, 1.7643e-05, 2.0444e-05, 9.8348e-06, 2.6703e-05, 2.6047e-05,\n",
      "        1.7762e-05, 1.8179e-05, 5.8770e-05, 6.0201e-06, 1.7107e-05, 2.0802e-05,\n",
      "        1.8775e-05], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<SelectBackward0>)\n",
      "Mean Train Loss: 0.6932\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2cca5772278407c836329721cef69ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/174 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Validation Loss: 0.6932\n",
      "Elapsed time: 36.26028167804082\n",
      "Checkpoint saved at ../results/swin-s-meta/checkpoint_2025-09-27_00-20-44.pth\n",
      "----- Epoch 8 -----\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3ece10614a94cb2a935e45a7dc78a0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/696 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last output: tensor([7.6890e-06, 5.9605e-06, 5.0664e-06, 4.7088e-06, 9.9540e-06, 4.8876e-06,\n",
      "        3.5167e-06, 4.2319e-06, 1.7881e-06, 7.7486e-06, 5.3644e-06, 5.4836e-06,\n",
      "        5.7817e-06], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<SelectBackward0>)\n",
      "Mean Train Loss: 0.6932\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9245bc163a84d21837689dc91dc78ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/174 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Validation Loss: 0.6931\n",
      "Elapsed time: 35.64291685024897\n",
      "Checkpoint saved at ../results/swin-s-meta/checkpoint_2025-09-27_00-20-44.pth\n",
      "Best checkpoint updated at ../results/swin-s-meta/best_checkpoint_2025-09-27_00-20-44.pth\n",
      "----- Epoch 9 -----\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2d3b4b52d5d43e0baf67c2853a70d22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/696 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last output: tensor([1.0729e-06, 7.7486e-07, 1.0729e-06, 5.9605e-07, 5.3644e-07, 1.1325e-06,\n",
      "        4.1127e-06, 1.6093e-06, 2.0862e-06, 1.7881e-06, 1.1921e-06, 9.5367e-07,\n",
      "        2.5630e-06], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<SelectBackward0>)\n",
      "Mean Train Loss: 0.6932\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36051f92c75b401d9595ef0a8e328f01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/174 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Validation Loss: 0.6931\n",
      "Elapsed time: 36.210670407613115\n",
      "Checkpoint saved at ../results/swin-s-meta/checkpoint_2025-09-27_00-20-44.pth\n",
      "----- Epoch 10 -----\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae0bcde7d4094f3ab0883385e9b344a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/696 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last output: tensor([1.2517e-06, 2.7418e-06, 1.3709e-06, 3.0398e-06, 7.4506e-06, 2.6226e-06,\n",
      "        2.3246e-06, 2.9802e-06, 1.5497e-06, 2.0266e-06, 1.6093e-06, 2.8610e-06,\n",
      "        1.3113e-06], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<SelectBackward0>)\n",
      "Mean Train Loss: 0.6931\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49889915699d4a83bc850081f4a28d00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/174 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Validation Loss: 0.6931\n",
      "Elapsed time: 36.23891297181447\n",
      "Checkpoint saved at ../results/swin-s-meta/checkpoint_2025-09-27_00-20-44.pth\n",
      "----- Epoch 11 -----\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b87197add5434bc8847e2a81dc107082",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/696 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last output: tensor([2.6822e-06, 2.3842e-06, 2.1458e-06, 2.9802e-06, 1.9073e-06, 1.6689e-06,\n",
      "        2.2650e-06, 2.0862e-06, 7.7486e-07, 2.1458e-06, 1.0729e-06, 4.8876e-06,\n",
      "        2.0862e-06], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<SelectBackward0>)\n",
      "Mean Train Loss: 0.6931\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14d72b5d4aa548b49a95de9aca5df070",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/174 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Validation Loss: 0.6931\n",
      "Elapsed time: 36.710558672746025\n",
      "Checkpoint saved at ../results/swin-s-meta/checkpoint_2025-09-27_00-20-44.pth\n",
      "Best checkpoint updated at ../results/swin-s-meta/best_checkpoint_2025-09-27_00-20-44.pth\n",
      "----- Epoch 12 -----\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c46b1881a372402c8f52b9627872691c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/696 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last output: tensor([1.7881e-07, 5.9605e-08, 3.5763e-07, 3.5763e-07, 1.7881e-07, 1.7881e-07,\n",
      "        2.9802e-07, 1.1921e-07, 1.1921e-07, 5.9605e-08, 1.1921e-07, 5.9605e-08,\n",
      "        1.7881e-07], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<SelectBackward0>)\n",
      "Mean Train Loss: 0.6931\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9367cace91d4894a3b702d72e16d32b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/174 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Validation Loss: 0.6931\n",
      "Elapsed time: 36.18319597641627\n",
      "Checkpoint saved at ../results/swin-s-meta/checkpoint_2025-09-27_00-20-44.pth\n",
      "Best checkpoint updated at ../results/swin-s-meta/best_checkpoint_2025-09-27_00-20-44.pth\n",
      "----- Epoch 13 -----\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41b3972214e245bab913c9b48665b171",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/696 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last output: tensor([1.0729e-06, 5.3644e-07, 1.4305e-06, 7.1526e-07, 1.3113e-06, 5.9605e-07,\n",
      "        1.4305e-06, 1.3709e-06, 8.3447e-07, 4.1723e-07, 3.5763e-07, 5.9605e-07,\n",
      "        1.1325e-06], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<SelectBackward0>)\n",
      "Mean Train Loss: 0.6931\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "250b9f2a62b244e9944404750a8366d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/174 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Validation Loss: 0.6931\n",
      "Elapsed time: 36.303755009174346\n",
      "Checkpoint saved at ../results/swin-s-meta/checkpoint_2025-09-27_00-20-44.pth\n",
      "Best checkpoint updated at ../results/swin-s-meta/best_checkpoint_2025-09-27_00-20-44.pth\n",
      "----- Epoch 14 -----\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "620367f870c64c29ad870cd7db6397a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/696 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last output: tensor([7.7486e-07, 9.5367e-07, 1.4901e-06, 1.6093e-06, 7.1526e-07, 1.1921e-06,\n",
      "        7.1526e-07, 9.5367e-07, 8.9407e-07, 1.0729e-06, 2.9802e-07, 5.9605e-07,\n",
      "        8.3447e-07], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<SelectBackward0>)\n",
      "Mean Train Loss: 0.6931\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54f373b22b444d57a30b0a705809aef4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/174 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Validation Loss: 0.6931\n",
      "Elapsed time: 36.68641512393951\n",
      "Checkpoint saved at ../results/swin-s-meta/checkpoint_2025-09-27_00-20-44.pth\n",
      "Best checkpoint updated at ../results/swin-s-meta/best_checkpoint_2025-09-27_00-20-44.pth\n",
      "----- Epoch 15 -----\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b7e3169b2f741d3bee63a388a249df6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/696 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last output: tensor([1.6093e-06, 1.9670e-06, 1.3709e-06, 1.6689e-06, 1.1325e-06, 2.3842e-06,\n",
      "        7.7486e-07, 7.7486e-07, 1.0729e-06, 1.3113e-06, 1.3709e-06, 1.4305e-06,\n",
      "        1.5497e-06], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<SelectBackward0>)\n",
      "Mean Train Loss: 0.6931\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1abf8eef59444ab6b6be62cb748d214e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/174 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Validation Loss: 0.6931\n",
      "Elapsed time: 36.07976760069529\n",
      "Checkpoint saved at ../results/swin-s-meta/checkpoint_2025-09-27_00-20-44.pth\n",
      "----- Epoch 16 -----\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7357bd41299d45258eb52d37551048d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/696 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last output: tensor([1.7881e-07, 2.3842e-07, 4.7684e-07, 2.3842e-07, 1.7881e-07, 7.1526e-07,\n",
      "        2.9802e-07, 2.3842e-07, 1.7881e-07, 2.3842e-07, 1.7881e-07, 1.7881e-07,\n",
      "        1.1921e-07], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<SelectBackward0>)\n",
      "Mean Train Loss: 0.6931\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e9bff2535d543598757613ef26d95e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/174 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Validation Loss: 0.6931\n",
      "Elapsed time: 35.92095851500829\n",
      "Checkpoint saved at ../results/swin-s-meta/checkpoint_2025-09-27_00-20-44.pth\n",
      "----- Epoch 17 -----\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1a42a2ecba14b91ae1b67da8a607a4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/696 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last output: tensor([4.7684e-07, 4.1723e-07, 2.3842e-07, 3.5763e-07, 1.1921e-07, 5.9605e-07,\n",
      "        2.3842e-07, 2.3842e-07, 4.1723e-07, 5.3644e-07, 2.3842e-07, 2.9802e-07,\n",
      "        3.5763e-07], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<SelectBackward0>)\n",
      "Mean Train Loss: 0.6931\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c48cfd95f21c49fa9f2160495b3e07de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/174 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Validation Loss: 0.6931\n",
      "Elapsed time: 36.07723657687505\n",
      "Checkpoint saved at ../results/swin-s-meta/checkpoint_2025-09-27_00-20-44.pth\n",
      "----- Epoch 18 -----\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c46516af652c425f98d130a81c55816d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/696 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last output: tensor([2.9206e-06, 3.6359e-06, 2.5630e-06, 2.4438e-06, 4.2319e-06, 1.1921e-06,\n",
      "        2.6822e-06, 1.9073e-06, 2.5034e-06, 2.2054e-06, 5.0664e-06, 2.5034e-06,\n",
      "        1.9670e-06], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<SelectBackward0>)\n",
      "Mean Train Loss: 0.6931\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40236105c6a046a4aba6da3b61e22520",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/174 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Validation Loss: 0.6931\n",
      "Elapsed time: 36.087802962462106\n",
      "Checkpoint saved at ../results/swin-s-meta/checkpoint_2025-09-27_00-20-44.pth\n",
      "----- Epoch 19 -----\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb6012d65c874202ada67d9b0222760f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/696 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last output: tensor([5.9605e-08, 1.1921e-07, 0.0000e+00, 5.9605e-08, 5.9605e-08, 5.9605e-08,\n",
      "        5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 1.1921e-07,\n",
      "        5.9605e-08], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<SelectBackward0>)\n",
      "Mean Train Loss: 0.6931\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7862521bbf0c4be1b66aed4ce6d322bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/174 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Validation Loss: 0.6931\n",
      "Elapsed time: 36.0509335398674\n",
      "Checkpoint saved at ../results/swin-s-meta/checkpoint_2025-09-27_00-20-44.pth\n",
      "----- Epoch 20 -----\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed20e2ba6bbc4c849a99111d5233e143",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/696 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last output: tensor([1.3113e-06, 2.9802e-07, 7.7486e-07, 8.3447e-07, 1.4901e-06, 1.2517e-06,\n",
      "        2.0862e-06, 7.1526e-07, 8.3447e-07, 1.6093e-06, 1.1921e-06, 1.1921e-06,\n",
      "        1.2517e-06], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<SelectBackward0>)\n",
      "Mean Train Loss: 0.6931\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93fd90d1c3554e8ebc6e39222bea43fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/174 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Validation Loss: 0.6931\n",
      "Elapsed time: 34.32629758516948\n",
      "Checkpoint saved at ../results/swin-s-meta/checkpoint_2025-09-27_00-20-44.pth\n",
      "Best checkpoint updated at ../results/swin-s-meta/best_checkpoint_2025-09-27_00-20-44.pth\n",
      "Artifact was logged to W&B\n"
     ]
    }
   ],
   "source": [
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f94bd995",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m The nbformat package was not found. It is required to save notebook history.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>time</td><td>█▃▄▇██▆▄▆▆▇▆▆▇▅▅▅▅▅▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>time</td><td>34.3263</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">soft-energy-5</strong> at: <a href='https://wandb.ai/ataracsia/RSNA-IAD/runs/54y890ha' target=\"_blank\">https://wandb.ai/ataracsia/RSNA-IAD/runs/54y890ha</a><br> View project at: <a href='https://wandb.ai/ataracsia/RSNA-IAD' target=\"_blank\">https://wandb.ai/ataracsia/RSNA-IAD</a><br>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250927_002045-54y890ha\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if CFG.use_wandb:\n",
    "    run.finish()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
