{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-12T23:49:53.777034Z",
     "iopub.status.busy": "2024-06-12T23:49:53.776252Z",
     "iopub.status.idle": "2024-06-12T23:49:55.048899Z",
     "shell.execute_reply": "2024-06-12T23:49:55.047589Z",
     "shell.execute_reply.started": "2024-06-12T23:49:53.777Z"
    }
   },
   "source": [
    "# RSNA 2025 Intracranial Aneurysm Detection Create Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This notebook is to create the dataset from DICOM files to PNG files (224x224 px as default). You can adjust the size to suit your needs.\n",
    "\n",
    "**The dataset generated by this notebook can be found at : https://www.kaggle.com/datasets/dennisfong/rsna-2025-intracranial-aneurysm-png-224x224/**\n",
    "\n",
    "Files will be created to cvt_png folder with the following sturure:\n",
    "```plaintext\n",
    "cvt_png/\n",
    "├── <location_name>/\n",
    "│   ├── <SeriesInstanceUID_1>/\n",
    "│   │   ├── 0000.png\n",
    "│   │   ├── 0001.png\n",
    "│   │   ├── 0002.png\n",
    "│   │   └── ...\n",
    "│   ├── <SeriesInstanceUID_2>/\n",
    "│   │   ├── 0000.png\n",
    "│   │   ├── 0001.png\n",
    "│   │   └── ...\n",
    "│   └── ...\n",
    "├── <location_name_2>/\n",
    "│   ├── <SeriesInstanceUID_3>/\n",
    "│   │   ├── 0000.png\n",
    "│   │   ├── 0001.png\n",
    "│   │   └── ...\n",
    "│   └── ...\n",
    "└── ...\n",
    "```\n",
    "\n",
    "* train_localizers_with_relative.csv will be created to store the original information and relative information created for the converted PNG\n",
    "* series_index_mapping.csv maps each DICOM file in the dataset to its corresponding SeriesInstanceUID, SOPInstanceUID (derived from filename), Modality, and its relative position (index) within the sorted series."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このノートブックは、DICOMファイルからPNGファイル（デフォルトで224x224ピクセル）へのデータセットを作成するためのものです。必要に応じてサイズを調整できます。\n",
    "このノートブックで生成されたデータセットは以下で確認できます：https://www.kaggle.com/datasets/dennisfong/rsna-2025-intracranial-aneurysm-png-224x224/\n",
    "\n",
    "ファイルは以下の構造でcvt_pngフォルダ内に作成されます：\n",
    "- train_localizers_with_relative.csv：元の情報と変換済みPNG用に生成された相対情報を保存\n",
    "- series_index_mapping.csv：データセット内の各DICOMファイルを、対応するSeriesInstanceUID、SOPInstanceUID（ファイル名から導出）、Modality、およびソート済みシリーズ内の相対位置（インデックス）にマッピング"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenges in Processing DICOM Images for PNG Conversion\n",
    "**1. Handling Compressed DICOM Files**\n",
    "Many DICOM files use compression schemes that require specialized decoding libraries. Without proper decompression support, attempts to read pixel data will fail or produce invalid images. For instance, some transfer syntaxes require the use of the GDCM (Grassroots DICOM) library to decode compressed pixel data such as JPEG or JPEG2000. If GDCM is not available or not properly configured, the pipeline cannot process these compressed DICOM files.\n",
    "\n",
    "**2. Unsupported Image Channel Formats for OpenCV**\n",
    "OpenCV’s image writing function (cv2.imwrite) only supports images with 1 (grayscale), 3 (RGB), or 4 (RGBA) channels. However, DICOM pixel data may sometimes have unusual channel configurations, such as multi-frame images or color images with 2 or more than 4 channels (e.g., shape (height, width, 2) or beyond). This mismatch leads to errors or corrupt output since OpenCV cannot handle these unsupported channel formats directly.\n",
    "\n",
    "**3. Empty or Invalid DICOM Pixel Data Leading to Resize Failures**\n",
    "Some DICOM files may contain missing, corrupted, or empty pixel data. Attempting to resize such empty images results in runtime errors in OpenCV, specifically an assertion failure indicating that the target resize dimensions are empty or invalid. This commonly occurs when the pixel array is None or has zero size, causing the image processing pipeline to crash or terminate unexpectedly.\n",
    "\n",
    "**4. Incorrect Slice Ordering Due to Non-sequential Filenames**\n",
    "DICOM files are often named using unique identifiers such as SOPInstanceUID, which are not inherently ordered. Sorting files by filename—even using natural sorting—does not guarantee the correct anatomical or acquisition order of slices. This is critical in medical imaging, where proper spatial ordering is required for accurate visualization, 3D reconstruction, or volume analysis. Relying on alphabetical or natural file sorting can result in incorrect image sequences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PNG変換のためのDICOM画像処理における課題\n",
    "1. 圧縮DICOMファイルの処理多くのDICOMファイルは、専用のデコードライブラリを必要とする圧縮方式を使用しています。適切な復号サポートがない場合、ピクセルデータの読み取りは失敗するか、無効な画像を生成します。例えば、一部の転送構文では、JPEGやJPEG2000などの圧縮ピクセルデータをデコードするためにGDCM（Grassroots DICOM）ライブラリの使用が必要です。<span style=\"color:red\">GDCMが利用できない、または適切に設定されていない場合、パイプラインはこれらの圧縮DICOMファイルを処理できません</span>。\n",
    "2. OpenCVでサポートされていない画像チャンネル形式 OpenCVの画像書き込み関数（cv2.imwrite）は、1チャンネル（グレースケール）、3チャンネル（RGB）、または4チャンネル（RGBA）の画像のみをサポートします。しかし、<span style=\"color:red\">DICOMピクセルデータはマルチフレーム画像や2チャネル以上（例：shape(height, width, 2)以上）のカラー画像など、特殊なチャネル構成を持つ場合があります。OpenCVはこれらの非対応チャネル形式を直接処理できないため、不一致によりエラーや出力破損が発生します</span>。\n",
    "3. 空または無効なDICOMピクセルデータによるリサイズ失敗 一部のDICOMファイルには、欠落・破損・空のピクセルデータが含まれる場合があります。このような<span style\"color:red\">空の画像をリサイズしようとすると、OpenCVで実行時エラー（具体的には、ターゲットリサイズ寸法が空または無効であることを示すアサーション失敗）が発生します</span>。これはピクセル配列がNoneまたはサイズがゼロの場合に頻繁に発生し、画像処理パイプラインのクラッシュや予期せぬ終了を引き起こします。\n",
    "4. ファイル名の非連続性による不正確なスライス順序 DICOMファイルは、SOPInstanceUIDなどの固有識別子で命名されることが多く、これらは本質的に順序付けられていません。<span style=\"color:red\">ファイル名を基準にファイルを並べ替えること（自然順ソートを含む）は、スライスの解剖学的順序や取得順序の正確性を保証しません</span>。これは、正確な可視化、3D再構築、またはボリューム解析に適切な空間的順序が必要な医療画像において重大な問題です。アルファベット順や自然なファイルソートに依存すると、誤った画像シーケンスが生じる可能性があります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solutions to Address These Challenges\n",
    "**1. Integrate GDCM for Compressed DICOM Decoding**\n",
    "Ensure that the GDCM library is installed and integrated with the pydicom pixel data handlers. (Special thanks to @ronaldokun on providing GDCM offline version)\n",
    "\n",
    "\n",
    "**2. Normalize or Convert Pixel Data to Supported Formats**\n",
    "Before passing image data to OpenCV functions, inspect the shape of the pixel array. For unsupported channel numbers:\n",
    "\n",
    "* Convert color spaces as needed (e.g., YBR_FULL to RGB).\n",
    "\n",
    "* For multi-channel or multi-frame images, extract or merge frames to produce a single 1-, 3-, or 4-channel image.\n",
    "\n",
    "* Convert to grayscale if color conversion is ambiguous or unsupported.\n",
    "\n",
    "This preprocessing ensures the final image conforms to OpenCV requirements, avoiding runtime errors during saving or display.\n",
    "\n",
    "**3. Validate and Handle Empty or Corrupt Pixel Data Gracefully**\n",
    "Add explicit checks after loading pixel data to verify it is non-empty and valid before any resizing or processing. If pixel data is missing or empty, skip processing the image with appropriate logging or error handling. This prevents crashes and allows the pipeline to continue processing other valid files.\n",
    "\n",
    "**4. Robust Multi-Criterion DICOM Sorting**\n",
    "\n",
    "To ensure reliable ordering, we employ a two-level sorting strategy using metadata from each DICOM file:\n",
    "\n",
    "a. **Primary Criterion: InstanceNumber**\n",
    "\n",
    "This DICOM tag (0020,0013) is the most commonly used and directly indicates the order of acquisition or frame.\n",
    "\n",
    "If InstanceNumber is present, it is used as the primary key for sorting.\n",
    "\n",
    "b. **Secondary Criterion: ImagePositionPatient**\n",
    "\n",
    "If InstanceNumber is missing or unreliable, we fall back to the Z-coordinate ([2]) of ImagePositionPatient (0020,0032), which represents the spatial position of the slice along the patient’s body axis.\n",
    "\n",
    "This is especially useful for CT/MR scans when spatial consistency is required.\n",
    "\n",
    "c. **Fallback Behavior**\n",
    "\n",
    "If neither tag is available, the file is assigned a very large sorting key (float('inf')), effectively pushing it to the end of the list.\n",
    "\n",
    "This ensures that invalid or unreadable files do not interfere with the valid sorting logic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これらの課題への解決策\n",
    "1. 圧縮DICOMデコードのためのGDCM統合 <span style=\"color:deepskyblue\">GDCMライブラリがインストールされ、pydicomピクセルデータハンドラーと統合されていることを確認</span>してください。（GDCMオフライン版を提供してくださった@ronaldokunに感謝）\n",
    "2. ピクセルデータを正規化またはサポート形式に変換 <span style=\"color:deepskyblue\">画像データをOpenCV関数に渡す前に、ピクセル配列の形状を確認する。サポートされていないチャンネル数の場合：\n",
    "必要に応じて色空間を変換する（例：YBR_FULLからRGBへ）。\n",
    "マルチチャンネルまたはマルチフレーム画像の場合：フレームを抽出または結合し、単一の1、3、または4チャンネル画像を生成します。\n",
    "カラー変換が不明確または非対応の場合：グレースケールに変換</span>します。\n",
    "この前処理により、最終画像がOpenCVの要件に適合し、保存時や表示時のランタイムエラーを回避できます。\n",
    "3. 空または破損したピクセルデータの検証と適切な処理 ピクセルデータ読み込み後に明示的なチェックを追加し、リサイズや処理前にデータが空でないこと、かつ有効であることを確認します。<span style=\"color:deepskyblue\">ピクセルデータが欠落または空の場合、適切なログ記録またはエラー処理を行い、画像の処理をスキップ</span>します。これによりクラッシュを防ぎ、パイプラインが他の有効なファイルの処理を継続できるようにします。\n",
    "4. 堅牢な多基準DICOMソート\n",
    "<span style=\"color:deepskyblue\">信頼性の高い順序付けを確保するため、各DICOMファイルのメタデータを用いた2段階ソート戦略を採用</span>します：\n",
    "a. 主要基準：InstanceNumber\n",
    "このDICOMタグ（0020,0013）は最も一般的に使用され、取得順序またはフレーム順を直接示します。\n",
    "InstanceNumberが存在する場合、これをソートの主キーとして使用します。\n",
    "b. 副次基準：ImagePositionPatient\n",
    "InstanceNumberが欠落または信頼できない場合、ImagePositionPatient（0020,0032）のZ座標([2])にフォールバックします。これは患者の身体軸に沿ったスライスの空間的位置を表します。\n",
    "これは、空間的な一貫性が要求される CT/MR スキャンで特に有用です。\n",
    "c. フォールバック動作\n",
    "どちらのタグも利用できない場合、ファイルには非常に大きなソートキー (float(『inf』)) が割り当てられ、事実上リストの最後に追いやられます。\n",
    "これにより、無効または読み取り不可能なファイルが、有効なソートロジックに干渉することがなくなります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-12T06:25:56.420391Z",
     "iopub.status.busy": "2025-09-12T06:25:56.419355Z",
     "iopub.status.idle": "2025-09-12T06:25:56.437705Z",
     "shell.execute_reply": "2025-09-12T06:25:56.436287Z",
     "shell.execute_reply.started": "2025-09-12T06:25:56.420340Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "DEBUG = False  # Set to False to run on full dataset\n",
    "GLOBAL_WIDTH = 256 # the width is of the same size as height\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install and import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-12T06:25:56.440794Z",
     "iopub.status.busy": "2025-09-12T06:25:56.440355Z",
     "iopub.status.idle": "2025-09-12T06:26:04.455249Z",
     "shell.execute_reply": "2025-09-12T06:26:04.453841Z",
     "shell.execute_reply.started": "2025-09-12T06:25:56.440752Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting dicomsdl\n",
      "  Downloading dicomsdl-0.109.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.9 kB)\n",
      "Downloading dicomsdl-0.109.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: dicomsdl\n",
      "Successfully installed dicomsdl-0.109.4\n"
     ]
    }
   ],
   "source": [
    "# !pip install dicomsdl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-12T06:26:04.457481Z",
     "iopub.status.busy": "2025-09-12T06:26:04.457075Z",
     "iopub.status.idle": "2025-09-12T06:26:10.242401Z",
     "shell.execute_reply": "2025-09-12T06:26:10.240943Z",
     "shell.execute_reply.started": "2025-09-12T06:26:04.457439Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-gdcm\n",
      "  Downloading python_gdcm-3.2.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (3.6 kB)\n",
      "Downloading python_gdcm-3.2.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (13.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.2/13.2 MB\u001b[0m \u001b[31m57.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: python-gdcm\n",
      "Successfully installed python-gdcm-3.2.1\n"
     ]
    }
   ],
   "source": [
    "# !pip install python-gdcm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-12T06:26:10.245814Z",
     "iopub.status.busy": "2025-09-12T06:26:10.245418Z",
     "iopub.status.idle": "2025-09-12T06:26:12.590216Z",
     "shell.execute_reply": "2025-09-12T06:26:12.588846Z",
     "shell.execute_reply.started": "2025-09-12T06:26:10.245774Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import glob\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import pydicom\n",
    "from pydicom.pixel_data_handlers.util import convert_color_space\n",
    "# import dicomsdl as dicoml\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "from IPython.display import HTML\n",
    "from multiprocessing import Pool, cpu_count\n",
    "import imageio\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some dicom files are compressed, we need to import the gdcm library to convert the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-12T06:26:12.593753Z",
     "iopub.status.busy": "2025-09-12T06:26:12.593000Z",
     "iopub.status.idle": "2025-09-12T06:26:13.177946Z",
     "shell.execute_reply": "2025-09-12T06:26:13.176455Z",
     "shell.execute_reply.started": "2025-09-12T06:26:12.593715Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gdcm/\n",
      "gdcm/conda-4.8.4-py37hc8dfbb8_2.tar.bz2\n",
      "gdcm/gdcm-2.8.9-py37h71b2a6d_0.tar.bz2\n",
      "gdcm/libjpeg-turbo-2.0.3-h516909a_1.tar.bz2\n",
      "/bin/bash: line 1: conda: command not found\n",
      "done installing gdcm\n"
     ]
    }
   ],
   "source": [
    "!cp ../input/gdcm-conda-install/gdcm.tar .\n",
    "!tar -xvzf gdcm.tar\n",
    "!conda install --offline ./gdcm/gdcm-2.8.9-py37h71b2a6d_0.tar.bz2\n",
    "print(\"done installing gdcm\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init some variables and helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-12T06:26:13.179936Z",
     "iopub.status.busy": "2025-09-12T06:26:13.179537Z",
     "iopub.status.idle": "2025-09-12T06:26:13.188026Z",
     "shell.execute_reply": "2025-09-12T06:26:13.185911Z",
     "shell.execute_reply.started": "2025-09-12T06:26:13.179897Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "rd = '/kaggle/input/rsna-intracranial-aneurysm-detection'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-12T06:26:13.190942Z",
     "iopub.status.busy": "2025-09-12T06:26:13.190477Z",
     "iopub.status.idle": "2025-09-12T06:26:13.217884Z",
     "shell.execute_reply": "2025-09-12T06:26:13.216654Z",
     "shell.execute_reply.started": "2025-09-12T06:26:13.190905Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def atoi(text):\n",
    "    return int(text) if text.isdigit() else text\n",
    "\n",
    "def natural_keys(text):\n",
    "    return [ atoi(c) for c in re.split(r'(\\d+)', text) ]\n",
    "\n",
    "\n",
    "def get_sort_key(path):\n",
    "    \"\"\"\n",
    "    Return a sorting key for a DICOM file based on:\n",
    "    1. InstanceNumber (preferred)\n",
    "    2. ImagePositionPatient's Z-axis (fallback)\n",
    "    3. Defaults to (inf, inf) if neither is available\n",
    "    \"\"\"\n",
    "    try:\n",
    "        ds = pydicom.dcmread(path, stop_before_pixels=True)\n",
    "\n",
    "        # Try to use InstanceNumber first\n",
    "        instance_number = getattr(ds, 'InstanceNumber', None)\n",
    "\n",
    "        # Fallback: use Z-coordinate of ImagePositionPatient\n",
    "        image_position = getattr(ds, 'ImagePositionPatient', None)\n",
    "        z_position = image_position[2] if image_position and len(image_position) == 3 else None\n",
    "\n",
    "        if instance_number is not None:\n",
    "            return (int(instance_number), 0)\n",
    "        elif z_position is not None:\n",
    "            return (float('inf'), float(z_position))\n",
    "        else:\n",
    "            return (float('inf'), float('inf'))\n",
    "\n",
    "    except Exception:\n",
    "        return (float('inf'), float('inf'))\n",
    "\n",
    "\n",
    "\n",
    "def extract_sort_key(path):\n",
    "    try:\n",
    "        ds = pydicom.dcmread(path, stop_before_pixels=True, force=True)\n",
    "        instance_number = getattr(ds, 'InstanceNumber', None)\n",
    "        position = getattr(ds, 'ImagePositionPatient', [None, None, None])\n",
    "        z = position[2] if position and len(position) == 3 else None\n",
    "\n",
    "        if instance_number is not None:\n",
    "            return (int(instance_number), 0, path)\n",
    "        elif z is not None:\n",
    "            return (float('inf'), float(z), path)\n",
    "        else:\n",
    "            return (float('inf'), float('inf'), path)\n",
    "    except:\n",
    "        return (float('inf'), float('inf'), path)\n",
    "\n",
    "def fast_sort_dicom_paths_parallel(dcm_paths, num_workers=None):\n",
    "    if num_workers is None:\n",
    "        num_workers = max(1, cpu_count() - 1)\n",
    "\n",
    "    with Pool(processes=num_workers) as pool:\n",
    "        sort_info = pool.map(extract_sort_key, dcm_paths)\n",
    "\n",
    "    sort_info.sort()\n",
    "    return [x[2] for x in sort_info]\n",
    "\n",
    "# === Function to sort DICOM paths using metadata ===\n",
    "def fast_sort_dicom_paths(dcm_paths):\n",
    "    sort_info = []\n",
    "    for path in dcm_paths:\n",
    "        try:\n",
    "            ds = pydicom.dcmread(path, stop_before_pixels=True, force=True)\n",
    "            instance_number = getattr(ds, 'InstanceNumber', None)\n",
    "            position = getattr(ds, 'ImagePositionPatient', [None, None, None])\n",
    "            z = position[2] if position and len(position) == 3 else None\n",
    "\n",
    "            if instance_number is not None:\n",
    "                sort_info.append((int(instance_number), 0, path))\n",
    "            elif z is not None:\n",
    "                sort_info.append((float('inf'), float(z), path))\n",
    "            else:\n",
    "                sort_info.append((float('inf'), float('inf'), path))\n",
    "        except:\n",
    "            sort_info.append((float('inf'), float('inf'), path))\n",
    "    sort_info.sort()\n",
    "    return [x[2] for x in sort_info]\n",
    "\n",
    "# === Helper function for parallel sorting ===\n",
    "def sort_series(args):\n",
    "    series_uid, paths = args\n",
    "    sorted_paths = fast_sort_dicom_paths(paths)\n",
    "    return series_uid, sorted_paths\n",
    "\n",
    "def apply_dicom_windowing(img, window_center, window_width):\n",
    "    \"\"\"\n",
    "    Apply DICOM windowing to the input image. Windowing is a technique used in medical imaging \n",
    "    to enhance the visibility of specific structures or tissue types by adjusting the pixel intensity range.\n",
    "    \n",
    "    The windowing process involves clipping pixel values outside a specific range (defined by \n",
    "    window center and width) and then normalizing the image to a common intensity scale (0-255) for visualization.\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    img : np.ndarray\n",
    "        The input image to which windowing is applied. It should be a NumPy array (2D for grayscale images).\n",
    "        \n",
    "    window_center : float\n",
    "        The center value of the windowing. Typically, this represents the central intensity value for a certain tissue type.\n",
    "        \n",
    "    window_width : float\n",
    "        The width of the window. It defines the range of pixel values that will be included in the windowing process. \n",
    "        A wider window includes more intensities, while a narrower window emphasizes a smaller range.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    np.ndarray\n",
    "        The windowed image, scaled to 8-bit values (0-255) and returned as a NumPy array.\n",
    "    \"\"\"\n",
    "    # Calculate the minimum and maximum pixel values for the window\n",
    "    img_min = window_center - window_width // 2\n",
    "    img_max = window_center + window_width // 2\n",
    "    \n",
    "    # Clip the pixel values to the windowed range\n",
    "    img = np.clip(img, img_min, img_max)\n",
    "    \n",
    "    # Normalize the image to 0-1 range to prepare for scaling\n",
    "    img = (img - img_min) / (img_max - img_min + 1e-7)  # Adding a small epsilon to avoid division by zero\n",
    "    \n",
    "    # Scale the image to 8-bit (0-255) and return\n",
    "    return (img * 255).astype(np.uint8)\n",
    "\n",
    "def get_windowing_params(modality):\n",
    "    \"\"\"\n",
    "    Get the appropriate windowing parameters (center and width) based on the DICOM modality.\n",
    "    \n",
    "    Different modalities like CT, MRI, and MRA have different standard windowing values \n",
    "    to enhance specific tissue types or structures. For example, CT might have a window for bone, \n",
    "    while MRI might have a window for soft tissues.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    modality : str\n",
    "        The imaging modality (e.g., 'CT', 'MRI', 'CTA'). This determines which set of windowing parameters to use.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    Tuple[float, float]\n",
    "        A tuple containing the window center and window width for the given modality.\n",
    "    \"\"\"\n",
    "    # Dictionary mapping modalities to windowing parameters (center, width)\n",
    "    windows = {\n",
    "        'CT': (40, 80),     # Windowing parameters for CT images (e.g., bone/window for soft tissue)\n",
    "        'CTA': (50, 350),   # CTA (CT Angiography) has larger window width to visualize blood vessels\n",
    "        'MRA': (600, 1200), # MRA (Magnetic Resonance Angiography) uses a different range for blood vessels\n",
    "        'MRI': (40, 80),    # MRI typically uses windowing similar to CT for soft tissue\n",
    "        'MRI T2': (40, 80),\n",
    "        'MRI T1post': (40, 80),\n",
    "    }\n",
    "    \n",
    "    # Return the windowing parameters for the modality, defaulting to CT parameters if modality is not found\n",
    "    return windows.get(modality, (40, 80))  # Default to CT windowing if modality is unknown\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cache files sorting in each series for fast retrieval "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "高速検索のために各シリーズごとにファイルをキャッシュする\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-12T06:26:13.219790Z",
     "iopub.status.busy": "2025-09-12T06:26:13.219334Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRODUCTION MODE: Using all series_uids\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sorting DICOM series:  17%|█▋        | 760/4348 [07:38<51:32,  1.16it/s]  "
     ]
    }
   ],
   "source": [
    "# === Load train.csv ===\n",
    "df_train = pd.read_csv('/kaggle/input/rsna-intracranial-aneurysm-detection/train.csv')\n",
    "series_uids_full = df_train['SeriesInstanceUID'].unique()\n",
    "\n",
    "if DEBUG:\n",
    "    print(\"DEBUG MODE: Using only first 10 series_uids\")\n",
    "    series_uids = series_uids_full[:10]\n",
    "else:\n",
    "    print(\"PRODUCTION MODE: Using all series_uids\")\n",
    "    series_uids = series_uids_full\n",
    "\n",
    "# === Build map: SeriesInstanceUID → list of DICOM paths ===\n",
    "series_dicom_map = {\n",
    "    si: glob.glob(os.path.join(rd, 'series', si, '*.dcm'))\n",
    "    for si in series_uids\n",
    "}\n",
    "\n",
    "# === Parallel sort each series ===\n",
    "with Pool(cpu_count()) as pool:\n",
    "    sorted_results = list(tqdm(pool.imap(sort_series, series_dicom_map.items()),\n",
    "                               total=len(series_dicom_map),\n",
    "                               desc=\"Sorting DICOM series\"))\n",
    "\n",
    "# === Generate output rows ===\n",
    "rows = []\n",
    "for series_uid, sorted_paths in tqdm(sorted_results, desc=\"Generating CSV rows\"):\n",
    "    modality = df_train[df_train['SeriesInstanceUID'] == series_uid]['Modality'].iloc[0]  # Get modality for the current series\n",
    "    for idx, path in enumerate(sorted_paths):\n",
    "        sop_uid = os.path.splitext(os.path.basename(path))[0]  # use filename as SOPInstanceUID\n",
    "        rows.append({\n",
    "            'SeriesInstanceUID': series_uid,\n",
    "            'SOPInstanceUID': sop_uid,\n",
    "            'dicom_filename': path,\n",
    "            'relative_index': idx,\n",
    "            'Modality': modality\n",
    "        })\n",
    "\n",
    "# === Save as DataFrame ===\n",
    "df_series_index_mapping = pd.DataFrame(rows)\n",
    "df_series_index_mapping = df_series_index_mapping.sort_values(\n",
    "    by=['SeriesInstanceUID', 'relative_index']\n",
    ")\n",
    "df_series_index_mapping.to_csv('series_index_mapping.csv', index=False)\n",
    "print(\"Saved series_index_mapping.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_localizers = pd.read_csv(f'{rd}/train_localizers.csv')\n",
    "df_localizers.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(f'{rd}/train.csv')\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df['SeriesInstanceUID'].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export png from dcm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "UNCOMPRESSED_SYNTAXES = [\n",
    "    '1.2.840.10008.1.2',       # Implicit VR Little Endian\n",
    "    '1.2.840.10008.1.2.1',     # Explicit VR Little Endian\n",
    "    '1.2.840.10008.1.2.2',     # Explicit VR Big Endian\n",
    "]\n",
    "\n",
    "def dicom_to_png(src_path, dst_path, width=224, to_rgb=False, apply_windowing=False, modality='CT'):\n",
    "    try:\n",
    "        dicom = pydicom.dcmread(src_path, force=True)\n",
    "\n",
    "        if 'PixelData' not in dicom:\n",
    "            print(f\"[SKIP] No pixel data in: {src_path}\")\n",
    "            return\n",
    "\n",
    "        tsuid = dicom.file_meta.TransferSyntaxUID  # compression could be indicated here\n",
    "        # PixelSequence::copyDecodedFrameData - error in decoding frame data 'Unsupported marker type 0x64'\n",
    "\n",
    "        img = dicom.pixel_array\n",
    "        interp = dicom.PhotometricInterpretation\n",
    "\n",
    "        # Handle YBR color space\n",
    "        if interp == \"YBR_FULL\":\n",
    "            img = convert_color_space(img, 'YBR_FULL', 'RGB')\n",
    "\n",
    "        # Convert color to grayscale\n",
    "        if img.ndim == 3:\n",
    "            if interp in [\"RGB\", \"YBR_FULL\"]:\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "            elif img.shape[2] == 1:\n",
    "                img = img[:, :, 0]\n",
    "            elif img.shape[2] > 3:\n",
    "                img = img[:, :, 0]  # Fallback: take the first channel\n",
    "\n",
    "        # If windowing is requested, apply it\n",
    "        if apply_windowing:\n",
    "            window_center, window_width = get_windowing_params(modality)\n",
    "            img = apply_dicom_windowing(img, window_center, window_width)\n",
    "\n",
    "        # Normalize the image\n",
    "        img = img.astype(np.float32)\n",
    "        img_min, img_max = img.min(), img.max()\n",
    "        if img_max > img_min:\n",
    "            img = (img - img_min) / (img_max - img_min)\n",
    "        else:\n",
    "            img[:] = 0  # Flat image\n",
    "\n",
    "        # MONOCHROME1 means low values = white, invert it\n",
    "        if interp == \"MONOCHROME1\":\n",
    "            img = 1 - img\n",
    "\n",
    "        # Scale to 8-bit and resize\n",
    "        img = (img * 255).astype(np.uint8)\n",
    "\n",
    "        if img is None or img.size == 0:\n",
    "            print(f\"[SKIP] Invalid image data in: {src_path}\")\n",
    "            return\n",
    "\n",
    "        # Resize safely\n",
    "        try:\n",
    "            img = cv2.resize(img, (width, width))\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] Resize failed: {src_path} | {e}\")\n",
    "            return\n",
    "\n",
    "        # Convert grayscale to RGB if requested\n",
    "        if to_rgb:\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "        # Ensure destination directory exists\n",
    "        os.makedirs(os.path.dirname(dst_path), exist_ok=True)\n",
    "\n",
    "        # Save the image\n",
    "        cv2.imwrite(dst_path, img)\n",
    "        # print(f\"[OK] Saved: {dst_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Failed to process {src_path}: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "seriesInst_ids = df['SeriesInstanceUID'].unique()\n",
    "seriesInst_ids[:3], len(seriesInst_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "modality = list(df['Modality'].unique())\n",
    "modality\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Columns to exclude\n",
    "exclude_cols = ['SeriesInstanceUID', 'PatientAge', 'PatientSex', 'Modality', 'Aneurysm Present']\n",
    "\n",
    "# Get list of columns excluding the specified ones\n",
    "location = [col for col in df.columns if col not in exclude_cols]\n",
    "\n",
    "print(location)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the maximum number of input DICOM files per series directory to decide whether {j:03d}.png is sufficient or if {j:04d}.png is needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "# Path to your input series directory\n",
    "series_base_dir = os.path.join(rd, 'series')\n",
    "\n",
    "max_dcm_count = 0\n",
    "series_with_max = None\n",
    "\n",
    "# Get all series folders\n",
    "series_dirs = glob.glob(os.path.join(series_base_dir, '*'))\n",
    "\n",
    "# Loop through each series folder and count .dcm files\n",
    "for series_dir in series_dirs:\n",
    "    dcm_files = glob.glob(os.path.join(series_dir, '*.dcm'))\n",
    "    count = len(dcm_files)\n",
    "    if count > max_dcm_count:\n",
    "        max_dcm_count = count\n",
    "        series_with_max = series_dir\n",
    "\n",
    "print(f\"Max number of DICOM files in a series: {max_dcm_count}\")\n",
    "print(f\"Series folder with max DICOMs: {series_with_max}\")\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load precomputed mapping CSV\n",
    "df_mapping = pd.read_csv('series_index_mapping.csv')\n",
    "\n",
    "outputList = []\n",
    "\n",
    "if DEBUG:\n",
    "    series_subset = seriesInst_ids[:10]\n",
    "    print(\"DEBUG MODE: Processing first 10 SeriesInstanceUIDs\")\n",
    "else:\n",
    "    # seriesInst_idsはSeriesInstanceUIDのユニーク値のリスト\n",
    "    series_subset = seriesInst_ids\n",
    "    print(\"PRODUCTION MODE: Processing all SeriesInstanceUIDs\")\n",
    "\n",
    "for idx, si in enumerate(tqdm(series_subset, total=len(series_subset))):\n",
    "    # dfはtrain.csv\n",
    "    pdf = df[df['SeriesInstanceUID'] == si]\n",
    "    \n",
    "    for _, row in pdf.iterrows():\n",
    "        # locationは部位の名前のリスト\n",
    "        location_exist = [col for col in location if row[col] == 1]\n",
    "        \n",
    "        if not location_exist:\n",
    "            continue  # Skip if no diseases found\n",
    "\n",
    "        for loca in location_exist:\n",
    "            loca_ = loca.replace('/', '_')  # Clean the name for file system\n",
    "            \n",
    "            # === Read DICOM list from CSV ===\n",
    "            df_series = df_mapping[df_mapping['SeriesInstanceUID'] == si]\n",
    "            df_series = df_series.sort_values(by='relative_index')\n",
    "\n",
    "            if df_series.empty:\n",
    "                continue\n",
    "\n",
    "            # Create output directory\n",
    "            out_dir = f'cvt_png/{loca_}/{si}'\n",
    "            os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "            for j, row_mapping in enumerate(df_series.itertuples(index=False)):\n",
    "                impath = row_mapping.dicom_filename\n",
    "                dst = f'{out_dir}/{j:04d}.png'\n",
    "                outputList.append({'impath': impath, 'dst': dst, 'modality': row_mapping.Modality})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print (\"Length of outputList : %d\" % len (outputList))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "outputList[:2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for img in outputList[:3]:\n",
    "    print(img)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create relative infos for the converted png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# === Load Mapping CSV ===\n",
    "df_mapping = pd.read_csv('series_index_mapping.csv')\n",
    "mapping_dict = {\n",
    "    (row['SeriesInstanceUID'], row['SOPInstanceUID']): (row['relative_index'], row['dicom_filename'])\n",
    "    for _, row in df_mapping.iterrows()\n",
    "}\n",
    "\n",
    "if DEBUG:\n",
    "    print(\"DEBUG MODE: Using only first 10 rows of df_localizers\")\n",
    "    df_coords = df_localizers.iloc[:10].copy()\n",
    "else:\n",
    "    print(\"PRODUCTION MODE: Using full df_localizers\")\n",
    "    df_coords = df_localizers.copy()\n",
    "\n",
    "# Output columns\n",
    "relative_indices = []\n",
    "relative_xs = []\n",
    "relative_ys = []\n",
    "\n",
    "# Process each row\n",
    "for idx, row in tqdm(df_coords.iterrows(), total=len(df_coords)):\n",
    "    key = (row['SeriesInstanceUID'], row['SOPInstanceUID'])\n",
    "\n",
    "    if key not in mapping_dict:\n",
    "        relative_indices.append(None)\n",
    "        relative_xs.append(None)\n",
    "        relative_ys.append(None)\n",
    "        continue\n",
    "\n",
    "    relative_index, dicom_path = mapping_dict[key]\n",
    "    relative_indices.append(relative_index)\n",
    "\n",
    "    try:\n",
    "        ds = pydicom.dcmread(dicom_path, stop_before_pixels=True)\n",
    "        h, w = int(ds.Rows), int(ds.Columns)\n",
    "\n",
    "        coords = row['coordinates']\n",
    "        if isinstance(coords, str):\n",
    "            coords = eval(coords)\n",
    "\n",
    "        x_rel = (coords['x'] / w) * GLOBAL_WIDTH\n",
    "        y_rel = (coords['y'] / h) * GLOBAL_WIDTH\n",
    "\n",
    "        relative_xs.append(x_rel)\n",
    "        relative_ys.append(y_rel)\n",
    "\n",
    "    except Exception as e:\n",
    "        relative_xs.append(None)\n",
    "        relative_ys.append(None)\n",
    "\n",
    "# Add columns back to DataFrame\n",
    "df_coords['relative_index'] = relative_indices\n",
    "df_coords['relative_x'] = relative_xs\n",
    "df_coords['relative_y'] = relative_ys\n",
    "\n",
    "# Save\n",
    "output_csv_path = f'train_localizers_with_relative.csv'\n",
    "df_coords.to_csv(output_csv_path, index=False)\n",
    "print(f\"Saved updated DataFrame with relative info to: {output_csv_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the PNG from DICOM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from multiprocessing import cpu_count\n",
    "n_cores = cpu_count()\n",
    "print(f'Number of Logical CPU cores: {n_cores}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "Parallel(n_jobs=n_cores)(\n",
    "    delayed(dicom_to_png)(img['impath'], img['dst'], GLOBAL_WIDTH, apply_windowing=True, modality=img['modality'])\n",
    "    for img in outputList\n",
    ")\n",
    "\n",
    "elapsed = time.time() - start_time\n",
    "\n",
    "# Format time nicely\n",
    "hours, rem = divmod(elapsed, 3600)\n",
    "minutes, seconds = divmod(rem, 60)\n",
    "print(f\"Total running time: {int(hours)}h {int(minutes)}m {seconds:.2f}s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# delete the offline gdcm to create the dataset for Kaggler's use\n",
    "\n",
    "# Delete folder if it exists\n",
    "folder_path = \"/kaggle/working/gdcm\"\n",
    "if os.path.exists(folder_path) and os.path.isdir(folder_path):\n",
    "    !rm -rf /kaggle/working/gdcm\n",
    "\n",
    "# Delete file if it exists\n",
    "file_path = \"/kaggle/working/gdcm.tar\"\n",
    "if os.path.exists(file_path) and os.path.isfile(file_path):\n",
    "    !rm -f /kaggle/working/gdcm.tar\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization of the Dicom and converted PNG with useful information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def show_dicom_and_png_with_info(row, df_meta, rd, box_size_resized=10):\n",
    "\n",
    "    # Load the series_index_mapping.csv once\n",
    "    df_index_map = pd.read_csv(\"/kaggle/working/series_index_mapping.csv\")\n",
    "\n",
    "    # Parse identifiers\n",
    "    series_uid = row['SeriesInstanceUID']\n",
    "    sop_uid = row['SOPInstanceUID']\n",
    "    rel_index = row['relative_index']\n",
    "    rel_x = row['relative_x']\n",
    "    rel_y = row['relative_y']\n",
    "    loca = row['location'].replace('/', '_')\n",
    "\n",
    "    # Get metadata row\n",
    "    df_row = df_meta[df_meta['SeriesInstanceUID'] == series_uid].iloc[0]\n",
    "    patient_age = df_row['PatientAge']\n",
    "    patient_sex = df_row['PatientSex']\n",
    "    modality = df_row['Modality']\n",
    "\n",
    "    # Aneurysm location columns\n",
    "    aneurysm_location_cols = [\n",
    "        \"Left Infraclinoid Internal Carotid Artery\", \"Right Infraclinoid Internal Carotid Artery\",\n",
    "        \"Left Supraclinoid Internal Carotid Artery\", \"Right Supraclinoid Internal Carotid Artery\",\n",
    "        \"Left Middle Cerebral Artery\", \"Right Middle Cerebral Artery\",\n",
    "        \"Anterior Communicating Artery\", \"Left Anterior Cerebral Artery\",\n",
    "        \"Right Anterior Cerebral Artery\", \"Left Posterior Communicating Artery\",\n",
    "        \"Right Posterior Communicating Artery\", \"Basilar Tip\",\n",
    "        \"Other Posterior Circulation\"\n",
    "    ]\n",
    "    aneurysm_locations = [col for col in aneurysm_location_cols if df_row.get(col, 0) == 1]\n",
    "\n",
    "    # === Load PNG ===\n",
    "    rel_index_int = int(rel_index)\n",
    "    png_path = f'cvt_png/{loca}/{series_uid}/{rel_index_int:04d}.png'\n",
    "    img_png = cv2.imread(png_path)\n",
    "    if img_png is None:\n",
    "        print(f\"[!] PNG not found: {png_path}\")\n",
    "        return\n",
    "    img_png = cv2.cvtColor(img_png, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Draw box on PNG\n",
    "    x1_png = int(rel_x - box_size_resized / 2)\n",
    "    y1_png = int(rel_y - box_size_resized / 2)\n",
    "    x2_png = int(rel_x + box_size_resized / 2)\n",
    "    y2_png = int(rel_y + box_size_resized / 2)\n",
    "    cv2.rectangle(img_png, (x1_png, y1_png), (x2_png, y2_png), (255, 0, 0), 2)\n",
    "\n",
    "    # === Load DICOM using CSV ===\n",
    "    df_series = df_index_map[df_index_map['SeriesInstanceUID'] == series_uid]\n",
    "    dicom_path_row = df_series[df_series['SOPInstanceUID'] == sop_uid]\n",
    "    if dicom_path_row.empty:\n",
    "        print(f\"[!] DICOM path not found in CSV for SOPInstanceUID: {sop_uid}\")\n",
    "        return\n",
    "\n",
    "    dicom_path = dicom_path_row['dicom_filename'].values[0]\n",
    "\n",
    "    try:\n",
    "        ds = pydicom.dcmread(dicom_path)\n",
    "        img_dcm = ds.pixel_array.astype(np.float32)\n",
    "        img_dcm = (img_dcm - img_dcm.min()) / (img_dcm.max() - img_dcm.min() + 1e-6)\n",
    "        img_dcm = (img_dcm * 255).astype(np.uint8)\n",
    "        img_dcm_rgb = cv2.cvtColor(img_dcm, cv2.COLOR_GRAY2RGB)\n",
    "    except Exception as e:\n",
    "        print(f\"[!] Error reading DICOM: {dicom_path} | {e}\")\n",
    "        return\n",
    "\n",
    "    # Draw box on DICOM\n",
    "    coords = row['coordinates']\n",
    "    if isinstance(coords, str):\n",
    "        coords = eval(coords)\n",
    "    x_orig = int(coords['x'])\n",
    "    y_orig = int(coords['y'])\n",
    "\n",
    "    h_dcm, w_dcm = img_dcm.shape\n",
    "    scale_x = w_dcm / GLOBAL_WIDTH\n",
    "    scale_y = h_dcm / GLOBAL_WIDTH\n",
    "    box_size_dcm_x = int(box_size_resized * scale_x)\n",
    "    box_size_dcm_y = int(box_size_resized * scale_y)\n",
    "\n",
    "    x1_dcm = max(0, int(x_orig - box_size_dcm_x / 2))\n",
    "    y1_dcm = max(0, int(y_orig - box_size_dcm_y / 2))\n",
    "    x2_dcm = min(w_dcm - 1, int(x_orig + box_size_dcm_x / 2))\n",
    "    y2_dcm = min(h_dcm - 1, int(y_orig + box_size_dcm_y / 2))\n",
    "    cv2.rectangle(img_dcm_rgb, (x1_dcm, y1_dcm), (x2_dcm, y2_dcm), (255, 0, 0), 2)\n",
    "\n",
    "    # === Plot ===\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "    fig.subplots_adjust(top=0.75)\n",
    "\n",
    "    info_line = f\"Modality: {modality} | Age: {patient_age} | Sex: {patient_sex}\"\n",
    "    aneurysm_line = (\n",
    "        \"Aneurysm Present in: \" + \", \".join(aneurysm_locations)\n",
    "        if aneurysm_locations else \"No Aneurysm Present\"\n",
    "    )\n",
    "    tech_line = f\"Series UID: {series_uid}\\nLocation: {loca} | Frame Index: {rel_index}\"\n",
    "\n",
    "    fig.suptitle(\n",
    "        f\"{info_line}\\n{aneurysm_line}\\n{tech_line}\",\n",
    "        fontsize=12, y=1.1, ha='center'\n",
    "    )\n",
    "\n",
    "    axes[0].imshow(img_dcm_rgb)\n",
    "    axes[0].set_title(\"Original DICOM\")\n",
    "    axes[0].set_xlabel(\"Pixels\")\n",
    "    axes[0].set_ylabel(\"Pixels\")\n",
    "    axes[0].grid(True, linestyle='--', linewidth=0.5)\n",
    "\n",
    "    axes[1].imshow(img_png)\n",
    "    axes[1].set_title(f\"Converted & Resized PNG ({GLOBAL_WIDTH}x{GLOBAL_WIDTH})\")\n",
    "    axes[1].set_xlabel(\"Pixels\")\n",
    "    axes[1].set_ylabel(\"Pixels\")\n",
    "    axes[1].grid(True, linestyle='--', linewidth=0.5)\n",
    "\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "for i in range(3):\n",
    "    show_dicom_and_png_with_info(df_coords.iloc[i], df, rd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def concat_dicom_series_to_image(series_uid, location=None, df_coords=None, rd='.', \n",
    "                                resize_shape=(GLOBAL_WIDTH, GLOBAL_WIDTH), box_size_resized=10,\n",
    "                                layout='vertical', show=True, save_path=None,\n",
    "                                use_png=False):\n",
    "    \"\"\"\n",
    "    Concatenate all images in a DICOM series (or converted PNGs) into a single visual strip or grid.\n",
    "\n",
    "    Args:\n",
    "        series_uid (str): SeriesInstanceUID to visualize.\n",
    "        location (str): Needed only if use_png=True. Disease location (for PNG folder path).\n",
    "        df_coords (pd.DataFrame or None): Coordinate info for box overlays.\n",
    "        rd (str): Root directory containing 'series' folder.\n",
    "        resize_shape (tuple): Target (width, height) for resizing each image.\n",
    "        box_size_resized (int): Box size (in resized image space).\n",
    "        layout (str): 'vertical', 'horizontal', or 'grid'.\n",
    "        show (bool): Whether to plot using matplotlib.\n",
    "        save_path (str or None): If set, saves the output image.\n",
    "        use_png (bool): If True, loads PNGs instead of DICOMs.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "\n",
    "    # Load index mapping from CSV\n",
    "    df_index = pd.read_csv('/kaggle/working/series_index_mapping.csv')\n",
    "    df_series = df_index[df_index['SeriesInstanceUID'] == series_uid]\n",
    "    dicom_paths = df_series.sort_values(by='relative_index')['dicom_filename'].tolist()\n",
    "\n",
    "    # Build coordinate map from df_coords\n",
    "    coord_map = {}\n",
    "    if df_coords is not None:\n",
    "        df_sub = df_coords[df_coords['SeriesInstanceUID'] == series_uid]\n",
    "        for _, row in df_sub.iterrows():\n",
    "            sop = row['SOPInstanceUID']\n",
    "            coords = row['coordinates']\n",
    "            if isinstance(coords, str):\n",
    "                coords = eval(coords)\n",
    "            coord_map[sop] = coords\n",
    "\n",
    "    images = []\n",
    "\n",
    "    if use_png:\n",
    "        if location is None:\n",
    "            raise ValueError(\"`location` must be provided when use_png=True\")\n",
    "\n",
    "        png_dir = os.path.join('/kaggle/working/cvt_png', location.replace('/', '_'), series_uid)\n",
    "        print(f\"Loading PNGs from: {png_dir}\")\n",
    "        png_paths = sorted(glob.glob(os.path.join(png_dir, '*.png')))\n",
    "        \n",
    "        if df_coords is not None:\n",
    "            df_sub = df_coords[df_coords['SeriesInstanceUID'] == series_uid]\n",
    "\n",
    "        for i, path in enumerate(png_paths):\n",
    "            img = cv2.imread(path)\n",
    "            if img is None:\n",
    "                continue\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            img_resized = cv2.resize(img, resize_shape)\n",
    "\n",
    "            if df_coords is not None:\n",
    "                match = df_sub[df_sub['relative_index'] == i]\n",
    "                if not match.empty:\n",
    "                    x = match.iloc[0]['relative_x']\n",
    "                    y = match.iloc[0]['relative_y']\n",
    "                    if pd.notna(x) and pd.notna(y):\n",
    "                        x1 = int(x - box_size_resized / 2)\n",
    "                        y1 = int(y - box_size_resized / 2)\n",
    "                        x2 = int(x + box_size_resized / 2)\n",
    "                        y2 = int(y + box_size_resized / 2)\n",
    "                        cv2.rectangle(img_resized, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
    "\n",
    "            images.append(img_resized)\n",
    "\n",
    "    else:\n",
    "        for path in dicom_paths:\n",
    "            try:\n",
    "                ds = pydicom.dcmread(path)\n",
    "                img = ds.pixel_array.astype(np.float32)\n",
    "                img = (img - img.min()) / (img.max() - img.min() + 1e-6)\n",
    "                img = (img * 255).astype(np.uint8)\n",
    "                img_rgb = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
    "                img_resized = cv2.resize(img_rgb, resize_shape)\n",
    "\n",
    "                sop = ds.SOPInstanceUID\n",
    "                if sop in coord_map:\n",
    "                    orig_h, orig_w = img.shape\n",
    "                    x_orig = coord_map[sop]['x']\n",
    "                    y_orig = coord_map[sop]['y']\n",
    "\n",
    "                    # Scale original coords to resized image\n",
    "                    x = int((x_orig / orig_w) * resize_shape[0])\n",
    "                    y = int((y_orig / orig_h) * resize_shape[1])\n",
    "\n",
    "                    x1 = int(x - box_size_resized / 2)\n",
    "                    y1 = int(y - box_size_resized / 2)\n",
    "                    x2 = int(x + box_size_resized / 2)\n",
    "                    y2 = int(y + box_size_resized / 2)\n",
    "                    cv2.rectangle(img_resized, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
    "\n",
    "                images.append(img_resized)\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to load DICOM: {path}: {e}\")\n",
    "                continue\n",
    "\n",
    "    if not images:\n",
    "        print(f\"[!] No images found for series: {series_uid}\")\n",
    "        return None\n",
    "\n",
    "    # Layout image\n",
    "    if layout == 'vertical':\n",
    "        final_image = cv2.vconcat(images)\n",
    "    elif layout == 'horizontal':\n",
    "        final_image = cv2.hconcat(images)\n",
    "    elif layout == 'grid':\n",
    "        grid_size = int(np.ceil(np.sqrt(len(images))))\n",
    "        while len(images) < grid_size ** 2:\n",
    "            images.append(np.zeros_like(images[0]))\n",
    "        rows = [\n",
    "            cv2.hconcat(images[i*grid_size:(i+1)*grid_size])\n",
    "            for i in range(grid_size)\n",
    "        ]\n",
    "        final_image = cv2.vconcat(rows)\n",
    "    else:\n",
    "        raise ValueError(\"layout must be 'vertical', 'horizontal', or 'grid'\")\n",
    "\n",
    "    if show:\n",
    "        plt.figure(figsize=(12, 12))\n",
    "        plt.imshow(final_image)\n",
    "        plt.title(f\"Series UID: {series_uid} (using {'PNG' if use_png else 'DICOM'})\")\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "    if save_path:\n",
    "        cv2.imwrite(save_path, cv2.cvtColor(final_image, cv2.COLOR_RGB2BGR))\n",
    "        print(f\"Saved: {save_path}\")\n",
    "\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# View entire series with annotation if coordinates available\n",
    "\n",
    "concat_dicom_series_to_image(\n",
    "    series_uid='1.2.826.0.1.3680043.8.498.10022796280698534221758473208024838831',\n",
    "    df_coords=df_coords,\n",
    "    rd=rd,\n",
    "    show=True,\n",
    "    use_png=False,\n",
    "    layout='grid'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "concat_dicom_series_to_image(\n",
    "    series_uid='1.2.826.0.1.3680043.8.498.10022796280698534221758473208024838831',\n",
    "    df_coords=df_coords,\n",
    "    rd=rd,\n",
    "    show=True,\n",
    "    location='Right Middle Cerebral Artery',\n",
    "    use_png=True,\n",
    "    layout='grid'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def animate_dicom_series_to_gif(series_uid, location=None, df_coords=None, rd='.',\n",
    "                                 resize_shape=(GLOBAL_WIDTH, GLOBAL_WIDTH), box_size_resized=10,\n",
    "                                 use_png=False, gif_path='aneurysm_trace.gif', duration=0.3):\n",
    "\n",
    "    frames = []\n",
    "\n",
    "    # === Step 1: Get all bounding boxes from df_coords ===\n",
    "    boxes_to_draw = []\n",
    "\n",
    "    if df_coords is not None:\n",
    "        df_sub = df_coords[df_coords['SeriesInstanceUID'] == series_uid]\n",
    "        for _, row in df_sub.iterrows():\n",
    "            if use_png:\n",
    "                rel_x = row.get('relative_x')\n",
    "                rel_y = row.get('relative_y')\n",
    "                if pd.notna(rel_x) and pd.notna(rel_y):\n",
    "                    x1 = int(rel_x - box_size_resized / 2)\n",
    "                    y1 = int(rel_y - box_size_resized / 2)\n",
    "                    x2 = int(rel_x + box_size_resized / 2)\n",
    "                    y2 = int(rel_y + box_size_resized / 2)\n",
    "                    boxes_to_draw.append((x1, y1, x2, y2))\n",
    "            else:\n",
    "                coords = row.get('coordinates')\n",
    "                if isinstance(coords, str):\n",
    "                    coords = eval(coords)\n",
    "                if isinstance(coords, dict):\n",
    "                    x = coords.get('x')\n",
    "                    y = coords.get('y')\n",
    "                    if x is not None and y is not None:\n",
    "                        boxes_to_draw.append((x, y))  # True (unscaled) position\n",
    "\n",
    "    # === Step 2: Read PNGs or DICOMs ===\n",
    "    if use_png:\n",
    "        if location is None:\n",
    "            raise ValueError(\"`location` must be provided when using PNGs.\")\n",
    "\n",
    "        png_dir = os.path.join('/kaggle/working/cvt_png', location.replace('/', '_'), series_uid)\n",
    "        png_paths = sorted(glob.glob(os.path.join(png_dir, '*.png')))\n",
    "\n",
    "        for path in png_paths:\n",
    "            img = cv2.imread(path)\n",
    "            if img is None:\n",
    "                continue\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            # Draw all bounding boxes\n",
    "            for x1, y1, x2, y2 in boxes_to_draw:\n",
    "                cv2.rectangle(img, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
    "\n",
    "            frames.append(img)\n",
    "\n",
    "    else:\n",
    "        # Load paths from CSV instead of glob\n",
    "        df_index = pd.read_csv('series_index_mapping.csv')\n",
    "        df_series = df_index[df_index['SeriesInstanceUID'] == series_uid]\n",
    "        dicom_paths = df_series.sort_values(by='relative_index')['dicom_filename'].tolist()\n",
    "\n",
    "        for path in dicom_paths:\n",
    "            try:\n",
    "                ds = pydicom.dcmread(path)\n",
    "                img = ds.pixel_array.astype(np.float32)\n",
    "                img = (img - img.min()) / (img.max() - img.min() + 1e-6)\n",
    "                img = (img * 255).astype(np.uint8)\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "                # Resize the image to target shape\n",
    "                h_orig, w_orig = img.shape[:2]\n",
    "                img = cv2.resize(img, resize_shape)\n",
    "\n",
    "                # Rescale original positions to resized image\n",
    "                scale_x = resize_shape[0] / w_orig\n",
    "                scale_y = resize_shape[1] / h_orig\n",
    "\n",
    "                for x_orig, y_orig in boxes_to_draw:\n",
    "                    x1 = int(x_orig * scale_x - box_size_resized / 2)\n",
    "                    y1 = int(y_orig * scale_y - box_size_resized / 2)\n",
    "                    x2 = int(x_orig * scale_x + box_size_resized / 2)\n",
    "                    y2 = int(y_orig * scale_y + box_size_resized / 2)\n",
    "                    cv2.rectangle(img, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
    "\n",
    "                frames.append(img)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Skipped {path}: {e}\")\n",
    "                continue\n",
    "\n",
    "    # === Step 3: Save GIF ===\n",
    "    if not frames:\n",
    "        print(f\"No frames to animate for {series_uid}\")\n",
    "        return\n",
    "\n",
    "    imageio.mimsave(gif_path, frames, duration=duration)\n",
    "    print(f\"GIF saved: {gif_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "animate_dicom_series_to_gif(\n",
    "    series_uid='1.2.826.0.1.3680043.8.498.10022796280698534221758473208024838831',\n",
    "    location='Right Middle Cerebral Artery',\n",
    "    df_coords=df_coords,\n",
    "    rd='/kaggle/input/rsna-intracranial-aneurysm-detection',\n",
    "    use_png=True,  # or False for original DICOMs\n",
    "    gif_path='aneurysm_trace.gif',\n",
    "    duration=0.4\n",
    ")\n",
    "\n",
    "#display gif\n",
    "\n",
    "gif_path = \"aneurysm_trace.gif\"\n",
    "HTML(f'<img src=\"{gif_path}\" style=\"max-width:100%;\"/>')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 13694723,
     "sourceId": 99552,
     "sourceType": "competition"
    },
    {
     "datasetId": 832340,
     "sourceId": 1421668,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
